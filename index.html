<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>muoten.github.io: Data (&amp;) Science (&amp;) ...</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/resume.min.css" rel="stylesheet">

</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">Data (&amp;) Science (&amp;)...</span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.png" alt="Profile picture or avatar">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#uncool">Uncool Data Science:</a>
        </li>
        <li>
          <ul>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#causal-inference">Causal inference</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#linear-models">Linear models</a>
            </li>
          </ul>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#covid19">COVID-19:</a>
        </li>
        <li>
          <ul>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#covid19-estimates">Context, analysis & simulations</a>
            </li>

            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#covid19-data">References</a>
            </li>
          </ul>
          <ul class="navbar-nav">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#others">Other topics:</a>
            </li>
            <li>
              <ul>
                 <li class="nav-item">
                  <a class="nav-link js-scroll-trigger" href="#audio2vec">Audio Fingerprints</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link js-scroll-trigger" href="#computervision">Computer Vision</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link js-scroll-trigger" href="#hacks">Hackathons/Demos</a>
                </li>
              </ul>
            </li>
          </ul>
        </ul>
      </div>
    </nav>

    <div class="container-fluid p-0">

      <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="about">
        <div class="w-100">
          <h4 style="font-family:'Arial Narrow';margin-bottom: 1.5rem">Data <small>(&amp;)</small> Science <small>(&amp;)</small> ...
          </h4>

          <p class="lead mb-1">personal projects and recommended links, considering that...
          </p>
          <ul>
            <li>
              <i>"essentially all models are wrong, but some are useful".</i> <a href="https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1740-9713.2010.00442.x">Box G.</a> et al.
            </li>
            <li>
              <i>"explicit better than implicit". <a href="https://www.python.org/dev/peps/pep-0020/">The Zen of Python</a> et al.
                (with <a href="https://resources.bibblio.org/hubfs/share/2018-01-24-RecSysLDN-Ravelin.pdf">
                  exceptions</a>).
                </i>
              </li>
            </ul>
            <p class="lead mb-5">I expect models being wrong, but their assumptions explicit.
            </p>
            <p><i>Last update</i>: <a href="#audio2vec">Audio fingerprints</a><sup><small>(15/09/2024)</small></sup></p>
            <p>And previously...</p>
          <ul>
          <li><a href="#causal-discovery-2">Causal wars: assumptions strike back</a><!--<sup><small>(17/06/2021)</small></sup>--></li>
          <li><a href="#linear-models">Regression to linear regression</a><!--<sup><small>(2/08/2020)</small></sup>--></li>
            <li><a href="#others">...</a></li>
          </ul>


            <!--<p>Moreover <a href="#covid19">COVID-19 sections</a>, with:
            </p>
            <ul>

              <li>
                Context on
                <a href="#covid19-estimates-cases">confirmed cases vs estimates</a><sup><small>(17/05/2020)</small></sup>, <a href="#covid19-estimates-deaths">mortality</a><i><sup><small>(10/04/2020)</small></sup></i>
              </li>

              <li><i>
                <a href="#covid19-seroprevalence-bias">seroprevalence bias analysis</a><sup><small>(21/05/2020)</small></sup>,
                <a href="#covid19-data">data sources</a><sup><small>(21/05/2020)</small></sup>
              </i>

            </li>

          </ul>
          -->

          <p>Feedback welcome!
          </p>

          <div class="social-icons">
            <a href="https://www.linkedin.com/in/enrique-otero-muras-0aab1a133">
              <i class="fab fa-linkedin-in"></i>
            </a>
            <a href="https://github.com/muoten">
              <i class="fab fa-github"></i>
            </a>
            <a href="https://twitter.com/eoteromuras">
              <i class="fab fa-twitter"></i>
            </a>
          </div>
          <p><br/>
            <i><small>Content layout based on
              <a href="https://github.com/BlackrockDigital/startbootstrap-resume">startbootstrap-resume</a>.
              Custom charts generated with <a href="https://plotly.com/python/plotly-express/">Plotly Express</a>.
            </small>
          </i>
        </p>
      </div>
    </section>



    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="uncool">
      <div class="w-100">

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">

            <h3 class="mb-3">Uncool Data Science</h3>

            <div id="causal-inference">

              <div id="causal-discovery-2" class="subheading mb-3">Causal Wars: episode II (or V?) - Assumptions Strike Back
              </div>

              <h6>(Written 13/12/2020, updated 17/06/2021. 10 min read)</h6>

              <p>After my first (somewhat disappointing) adventures in automatic
                <a href="#causal-discovery">causal discovery with CDT package</a>, I go back to the topic with new experiments. Trying to get a better understanding of the following:
              </p>
              <ul>
                <li>
                  the theoretical and practical <strong>limits</strong> of <strong>automatic causal discovery</strong> (also known as <i>structure learning</i>).
                </li>
                <li>
                  its relation with main <strong>assumptions</strong> required to estimate causal effects from observational data, with and without <strong>graphical models</strong>
                </li>
                <li>
                and the involved <strong>methods</strong> and specifics for the <strong>bivariate example</strong>.
                </li>
              </ul>

              <p>As there is some consensus on the need of assumptions to infer causality based on observational data,
                things get tricky about the details.
                Even researchers from different fields have diverse opinions on the preferible
                ways to express the requirements and limitations of the different methodologies: languages, notations, diagrams...
              For instance, Lauritzen on <a href="https://onlinelibrary.wiley.com/doi/10.1111/j.1467-9469.2004.03-200A.x">Discussion in Causality</a>
                identifies up to 4 different formalisms or <i>causal languages</i>:
                structural equations, graphical models, counterfactual random variables and potential outcomes
              </p>
              <p>It is also in question if it is possible to infer causality based on data and some automated algorithm. According to Judea Pearl:
              </p>
              <blockquote style='display: block;margin-top: 1em;margin-bottom: 1em;margin-left: 40px;margin-right: 40px; border:1px; content: open-quote;'>
              <i>"[...] machine learning systems, based
              only on associations, are prevented
              from reasoning about (novel) actions,
              experiments, and causal explanations."</i>
              </blockquote>
              <p>
               Pearl postulates a
                    <strong>three-level hierarchy</strong>, or "ladder of causation", where <i>"questions at level i (i =
      1, 2, 3) can be answered only if information from level j (j>=i) is available".</i>
      </p>
              <figure>
                <img src="img/7_tools_causal_inference_preprint.png" alt="7 tools of causal inference" style="border:1px solid black; width:80%;margin:auto;display:block">
                <figcaption style="text-align:center" >
                  <small>Source: <a href="https://ftp.cs.ucla.edu/pub/stat_ser/r481.pdf">
                    The Seven Tools of Causal Inference, with Reflections on Machine Learning, by Judea Pearl
                    </a>
                  </small>
                </figcaption>
              </figure>


<p>
  The logical consequence of Pearl's postulates is that automatic causal discovery based on observational data is not feasible in general.
  In other words, as Peters et al state in <a href="https://library.oapen.org/bitstream/handle/20.500.12657/26040/11283.pdf">
    Elements of Causal Inference</a>: "there is an ill-posed-ness due to the fact that
  even complete knowledge of an observational distribution usually does not determine the underlying causal model".
  Or according to <a href="https://arxiv.org/abs/1904.02826">Maclaren's et al</a>, causal estimators may be unstable, and
  "lack of stability implies that [...] an achievable statistical estimation target may prove impossible".
  But, <i>could automatic causal discovery be epistemically impossible in theory but useful in practice under any circumstances?</i>
  In other words, is it possible to infer causality based on observations, an algorithm and some <i>soft</i> assumptions
  that are not explicitly predefining a causal model?
</p>
<div class="subheading mb-2">May the graphical models be with you
</div>
<p>
  To answer properly the question we should, first of all, disambiguate the different meanings
  and goals of "causal inference", and even what a (causal) "model" is.
  Language ambiguity is a source of misunderstandings, even between the most brilliant people. As an example,
  the reply of Andrew Gelman to Pearl's controversial statements in the Book of Why:

  <blockquote style='display: block;margin-top: 1em;margin-bottom: 1em;margin-left: 40px;margin-right: 40px; border:1px; content: open-quote;'>
<i>"Pearl and Mackenzie write that statistics “became a model-blind data reduction enterprise.”
Hey! What the hell are you talking about?? I’m a statistician, I’ve been doing statistics for 30 years,
 working in areas ranging from politics to toxicology. “Model-blind data reduction”? That’s just bullshit.
 We use models all the time"</i>
  </blockquote>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">“The Book of Why” by Pearl and Mackenzie <a href="https://t.co/hEMzlDa4wU">https://t.co/hEMzlDa4wU</a></p>&mdash; Andrew Gelman (@StatModeling) <a href="https://twitter.com/StatModeling/status/1082639137780498432?ref_src=twsrc%5Etfw">January 8, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js"></script>

  <figure>
    <img src="img/sabres.gif" alt="the empire strikes back gif" style="border:1px solid black; width:80%;margin:auto;display:block">
    <figcaption style="text-align:center" >
      <small>Source: <a href="http://unfunnynerdtangent.com/2018/10/40-for-40-16-the-empire-strikes-back/">unfunnynerdtangent.com
        </a>
      </small>
    </figcaption>
  </figure>

<p>It's probably not obvious that <strong>"models"</strong> referred by Pearl are "causal models",
  preferible <strong>causal diagrams</strong>,
or any type of model that <strong>encodes causal information</strong> in a transparent and testable way.
As <i><a href="https://fabiandablander.com/r/Causal-Inference.html#structural-causal-models">
  Structured Causal Models</a></i> (SCMs) also do via assignment functions.
</p>
<p>
There are several types of probabilistic graphical models that express sets of conditional independence assumptions via graph structure, including Directed Acyclic Graphs (DAGs)
known as <i>bayesian networks</i>.
DAGs can describe every conditional dependence and independence between the represented variables
if <a href="https://library.oapen.org/bitstream/handle/20.500.12657/26040/11283.pdf#page=118">Markov and Faithfulness</a> hipothesis hold.
And benefit from expressiveness and <a href="https://arxiv.org/pdf/1304.1505.pdf">d-separation</a>, a criteria that involves checking
whether a set of vertices Z blocks all connections of a certain type between X and Y in a graph G,
and reduces statistical independencies to connectivity in graphs.
</p>
<p>
But we still need stronger assumptions beyond Markov condition, faithfulness and d-separation to have a <a href="https://cdn1.sph.harvard.edu/wp-content/uploads/sites/1268/2021/03/ciwhatif_hernanrobins_30mar21.pdf#page=79">
  causal DAG</a>. Whereas (probabilistic) DAGs entail observational distributions, causal DAGs entail interventional distributions.
In <a href="https://www.cmu.edu/dietrich/philosophy/docs/scheines/introtocausalinference.pdf">Scheines's</a> words:
</p>
              <blockquote style='display: block;margin-top: 1em;margin-bottom: 1em;margin-left: 40px;margin-right: 40px; border:1px; content: open-quote;'>
<i>"one  might  take  a  further  step  by  assuming  that  when  DAGs  are  interpreted  causally  the  Markov  condition  and  d-separation  are  in  fact  the  correct  connection  between  causal  structure  and  probabilistic  independence.
We  call  the  latter  assumption  the  Causal Markov condition"
</i>
</blockquote>
<p>
Moreover, the term "causal inference" can (ambiguously) refer both to <strong>causal learning</strong> or
<strong>causal reasoning</strong>.
The former being the inference of a causal model from observations or interventions. And the latter,
estimating outcomes or effects (at individual or population level) based on a predefined causal model.
</p>

<figure>
  <img src="img/elements_of_causal_inference_terminology.png" alt="Terminology on Elements of Causal Inference (Peters et al.)" style="border:1px solid black; width:80%;margin:auto;display:block">
  <figcaption style="text-align:center" >
    <small>Source: <a href="https://library.oapen.org/bitstream/handle/20.500.12657/26040/11283.pdf">Elements of Causal Inference (Peters et al.)
      </a>
    </small>
  </figcaption>
</figure>

<div class="subheading mb-2">identifiability criteria for causal effects from observations
</div>

<p>In relation to causal reasoning, an effect is identifiable if it can be estimated from data, given a set of assumptions.
  In case of Average Treatment Effect (ATE), also known as Average Causal Effect (ACE),
  the required assumptions for identifiability, to my understanding are:</p>
  <ul>
    <li>
      Conditional <strong>exchangeability</strong>. <i>Maybe the hypothesis with more possible enunciates and ambiguity I found.
        I recognize myself still unable to identify subtle differences between the following terms: ignorability, unconfoundness, selection on observables,
        conditional independence assumption (CIA), exogeneity, causal sufficiency... are all them exchangeable?
        Thanks to Miguel Hernán et al's <a href="https://cdn1.sph.harvard.edu/wp-content/uploads/sites/1268/2021/03/ciwhatif_hernanrobins_30mar21.pdf#page=110">
          Causal Inference Book
        </a>
        for shedding some light on this Tower of Babel full of synonyms and meronyms:</i>


  <blockquote style='display: block;margin-top: 1em;margin-bottom: 1em;margin-left: 40px;margin-right: 40px; border:1px; content: open-quote;'>
<i>"[...] conditional exchangeability [...] often referred as
“weak ignorability” or “ignorable
treatment assignment” in statistics (Rosenbaum and Rubin, 1983),
“selection on observables” in the
social sciences (Barnow et al.,
1980), and no “ommitted variable
bias” or “exogeneity” in econometrics (Imbens, 2004)"
</i>
</blockquote>
Or these words from <a href="https://clas.ucdenver.edu/marcelo-perraillon/sites/default/files/attached-files/w2_causal_inference_perraillon_0.pdf">
  Marcelo Perraillon's lectures</a>:
<blockquote style='display: block;margin-top: 1em;margin-bottom: 1em;margin-left: 40px;margin-right: 40px; border:1px; content: open-quote;'>
<i>"Jargon, jargon, jargon: This assumption comes in many names, the most
common perhaps is no unmeasured confounders. Other names: selection
on observables, exogeneity, conditional independence assumption (CIA),
ignorability"
</i>
</blockquote>
</li>
</ul>
<ul>
    <li>
      <strong>Consistency</strong> of treatment. And <strong>no interference</strong>.
      Combination of consistency and no interference is also known as
      <i>Stable Unit Treatment Value Assumption (SUTVA)</i> in (deterministic) <a href="http://www.stat.columbia.edu/~cook/qr33.pdf">
        potential outcomes</a>. See Neal's
        <a href="https://www.bradyneal.com/Introduction_to_Causal_Inference-Aug28_2020-Neal.pdf#page=20">Introduction to Causal Inference</a>.
    </li>
    <li>
      <strong>Positivity</strong> (a.k.a. <i>overlap</i> a.k.a. <i>common support</i>). Or existence of all posible values of treatment and outcome.
    </li>
  </ul>
<p>
  Given the previous assumptions hold, several identifiability methods can be used
  to convert our causal estimand in a statistical formula that does not contain
  any potential outcome or do-operator notation. The most usual is standardization with the
  <strong>adjustment formula</strong>, analogously derived as Robin's <i>g-formula</i>,
  Spirtes's <i>manipulated distribution</i> or Pearl's <i>truncated factorization</i>, and closely related to <i>backdoor criterion</i>.

  <blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;backdoor adjustment&quot; is more than a formula. It provides two things: 1) an adjustment formula (RHS) and 2) a license (backdoor condition) to apply it. When we compare this condition to the license provided by the g-formula the key difference between the two shines brightly.</p>&mdash; Judea Pearl (@yudapearl) <a href="https://twitter.com/yudapearl/status/1024245586214539264?ref_src=twsrc%5Etfw">July 31, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


  Another interrelated identifiability technique is the Inverse Probability Weighting (IPW). Both standardization and IPW allow
  generalized estimates in the entire population so they are also known as <i>G-methods</i>
  (where "G" stands for "generalized"). Whereas matching or restriction only provide estimates for subsets of our population.
</p>
<p>Anyway, we can use these methods without graphical models. As we don't require
    <a href="https://fabiandablander.com/r/Causal-Inference.html#counterfactuals">
    neither counterfactuals nor SCMs</a>, unless we are
  interested on individual effects.
  <!--So, as stated by <a href="https://arxiv.org/pdf/1907.07271.pdf">Guido Imbens</a>, "the Potential Outcome
  framework is more apprehensive about definite answers to such questions that depend delicately on individual-level heterogeneity".
--> However, it's hard to know if exchangeability holds without the help of causal DAGs and
    <i>d-separation</i> to apply the <strong>adjustment criterion</strong> (defined by <a href="https://arxiv.org/abs/1203.3515">Shpitser et al</a> as a generalization of Pearl's <i>backdoor criterion</i>).
    Moreover, in Pearl's words:
</p>
  <blockquote style='display: block;margin-top: 1em;margin-bottom: 1em;margin-left: 40px;margin-right: 40px; border:1px; content: open-quote;'>
<i>
    "it is always possible to replace assumptions made in SCM [Structural Causal Model] with equivalent,
    albeit cumbersome assumptions in PO [Potential Outcomes] language,
    and eventually come to the correct conclusions." But "rejection of graphs and structural models
    leaves investigators with no process-model guidance and, not surprisingly,
    it has resulted in a number of blunders which the PO community is not very proud of"
</i>
  </blockquote>
<p>
    As an example of these "blunders" or difficulties, Rubin, cocreator of Potential Outcomes framework, in relation to the concept of colliders or M-bias,
    claimed that <i>"to avoid conditioning on some observed covariates... is [...] nonscientific ad hockery"</i>.
More details on <a href="https://statmodeling.stat.columbia.edu/2020/01/27/causal-inference-in-ai-expressing-potential-outcomes-in-a-graphical-modeling-framework-that-can-be-fit-using-stan/#comment-1242930">
  David Rohde's comment</a> on Gelman's blog and Rohde et al article on
  <a href="https://gradientinstitute.org/blog/6">Causal Inference with Bayes Rule</a>.
Anyway, as Gelman recognises in the post refered on the previous section, qualitative models (as DAGs) are less usual in statisticians' work, and "we need both".
  </p>

  <p>To be fair, apparently even <a href="https://csss.uw.edu/files/working-papers/2013/wp128.pdf#page=142">Pearl himself made mistakes</a> in his proposal of unification of DAGs and counterfactuals.
    As Richardson's et al remarked when they proposed the <a href="https://csss.uw.edu/files/working-papers/2013/wp128.pdf">
      Single World Intervention Graphs (SWIG)</a>, claiming that:
    <blockquote style='display: block;margin-top: 1em;margin-bottom: 1em;margin-left: 40px;margin-right: 40px; border:1px; content: open-quote;'>
<i>
    We are in strong agreement with Pearl’s basic contention that directed
graphs are a very valuable tool for reasoning about causality, and by extension, potential outcomes. If anything our criticism of the approach to
synthesizing graphs and counterfactuals in (Pearl, 2000, 2009) is that it is
not ‘graphical enough’ [...]
</i>
</blockquote>

  <p>Furthermore, there exists several identifiability methods that do not exploit the assumption of conditional exchangeability to handle confounding.
    These methods rely on alternative (also unverifiable) assumptions. Examples of these alternative methods are <i>difference-in-differences</i>, <i>instrumental variables</i> or the <i>front-door criterion</i>.
    See Hernán's et al <a href="https://cdn1.sph.harvard.edu/wp-content/uploads/sites/1268/2021/03/ciwhatif_hernanrobins_30mar21.pdf#page=105">Causal Inference: What If</a>
    for more details.
  </p>

<div class="subheading mb-2">Identifiability of causal structure
</div>
            <p>Otherwise, Pearl, apparent denier of Machine Learning to perform causal reasoning, also opens the possibility to
              (automatic) <strong>causal discovery</strong>. In his <a href="https://ftp.cs.ucla.edu/pub/stat_ser/r481-reprint.pdf">
                7 Tools of Causal Inference</a> he proposes
              "systematic searches" under "certain circumstances" and "mild assumptions". Besides, he worked years ago with T.S. Verma
              in the <a href="https://arxiv.org/pdf/1303.5435.pdf">
              Inductive Causation (IC) algorithm</a> of <strong>structure learning</strong>.
              And he also refers to the method by Shimizu et al (2006) to discover causal directionality
              based on functional decomposition in linear model with nonGaussian distributions. A method known as
              <a href="https://www.jmlr.org/papers/volume7/shimizu06a/shimizu06a.pdf">
                 LiNGAM: linear non-Gaussian acyclic model for causal discovery.
               </a>
            </p>
            <p>So... let's do it!
            </p>
               <figure>
                 <img src="img/yoda.gif" alt="Yoda: do or do not. There is no try" style="border:1px solid black; width:80%;margin:auto;display:block">
                 <figcaption style="text-align:center" >
                   <small>Source: <a href="https://tenor.com/es/ver/yoda-do-it-or-not-man-up-your-pick-star-wars-gif-7566902/">tenor.com
                     </a>
                   </small>
                 </figcaption>
               </figure>

             <p>
              I focused on 2 methods for the bivariate case:
             </p>
               <ul>
                 <li><strong>Conditional Similarity Distribution</strong>: as it seemed the best candidate from an empirical point of view.
                   Because it performed better than the alternatives in my <a href="#causal-discovery">first quick experiment</a>.
                   Furthermore is was also part of the <a href="https://arxiv.org/pdf/1601.06680.pdf">Jarfo model</a> that scored 2nd place in the ChaLearn cause-effect Kaggle challenge in 2013.
                   This method assumes that "the shape of the conditional distribution <math><mtext>p(Y(X=x))</mtext></math>
                   tends to be very similar for different values of <math><mi>x</mi></math> if the random variable <math><mi>X</mi></math>
                   is the cause of <math><mi>Y</mi></math>".
                   It's related to the principles of <i>(physical) independence of cause and mechanism</i> (ICM) and
                   <i>algorithmic independence of conditionals</i>.
                   The last one states that the joint distribution has a shorter description in the true causal direction
                   than in the anticausal. In the spirit of Occam's razor. Unfortunately, Kolmogorov complexity is uncomputable,
                   so the Minimum Description Length in the sense of Kolmogorov "should be considered a philosophical principle
                   rather than a method". <i>See <a href="https://library.oapen.org/bitstream/handle/20.500.12657/26040/11283.pdf?sequence=1&isAllowed=y">
                     Elements of Causal Inference</a></i>.
                 </li>
                 <li><strong>Post-Nonlinear Causal Model</strong>: as it seems the more solid from an analytical point of view.
                   It even tries to explain the 5 circumstances in which their assumptions don't hold and it would fail.
                   Published by <a href="https://arxiv.org/pdf/1205.2599.pdf">Zhang et al in 2009</a>, it can be considered as a generalization of the so-called
                   <a href="https://papers.nips.cc/paper/2008/file/f7664060cc52bc6f3d620bcedc94a4b6-Paper.pdf">
                     additive noise model (ANM)</a> by Hoyer et al. Both are based on <i>a priori restrictions of the model class</i>.
                     For instance, assuming functions and probability densities three times differentiable.
                 </li>
                </ul>
                <p>
                  I used the <a href="https://webdav.tuebingen.mpg.de/cause-effect/">Tubingen cause-effect pairs dataset</a>.
                  As part of their 108 pairwise examples, it contains also relationship between Gross National Income
                  per capita and life expectancy.
                </p>
                <figure>
                  <img src="img/cds_score_example_0.png" alt="Gross National Income vs life expectancy" style="border:1px solid black; width:80%;margin:auto;display:block">
                  <figcaption style="text-align:center" >
                    <small>Source: <a href="https://github.com/muoten/causal-discovery-playground/blob/master/automatic_pairwise_causal_discovery_via_cds.ipynb">muoten.github.io
                      </a>
                    </small>
                  </figcaption>
                </figure>

          <p>Results:
          </p>
          <ul>
            <li>
            <a href="https://github.com/muoten/causal-discovery-playground/blob/master/automatic_pairwise_causal_discovery_via_cds.ipynb">Notebook 1: experiments on Conditional Similarity Distribution</a>
          </li>
          <li>
            <a href="https://github.com/muoten/causal-discovery-playground/blob/master/automatic_pairwise_causal_discovery_via_pnl.ipynb">Notebook 2 with experiments on Post-Nonlinear Causal Model</a>
          </li>
        </ul>
        <p>To be continued...
        </p>
          <figure>
            <img src="img/cds_score_example_1.png" alt="conditional distribution similarity score" style="border:1px solid black; width:80%;margin:auto;display:block">
            <figcaption style="text-align:center" >
              <small>Source: <a href="https://github.com/muoten/causal-discovery-playground/blob/master/automatic_pairwise_causal_discovery_via_cds.ipynb">muoten.github.io
                </a>
              </small>
            </figcaption>
          </figure>
          <figure>
            <img src="img/cds_score_example_2.png" alt="conditional distribution similarity score" style="border:1px solid black; width:80%;margin:auto;display:block">
            <figcaption style="text-align:center" >
              <small>Source: <a href="https://github.com/muoten/causal-discovery-playground/blob/master/automatic_pairwise_causal_discovery_via_cds.ipynb">muoten.github.io
                </a>
              </small>
            </figcaption>
          </figure>

            <br/>

            <h6>References</h6>
            <ul>
              <li>Pearl, J. (<a href="https://ftp.cs.ucla.edu/pub/stat_ser/r481.pdf">2018</a>,
                <a href="https://dl.acm.org/doi/pdf/10.1145/3241036">2019</a>).
                The seven tools of causal inference, with reflections on machine learning. Commun. ACM, 62(3), 54-60.
              </li>
              <li>
                Peters, J., Janzing, D., &amp; Schölkopf, B.
                (<a href="https://library.oapen.org/bitstream/handle/20.500.12657/26040/11283.pdf">2017</a>). Elements of Causal Inference: Foundations and Learning Algorithms. MIT Press.
              </li>
              <li>
                Maclaren, O.J., Nicholson, R. (<a href="https://arxiv.org/abs/1904.02826">2019</a>).
                  What can be estimated? Identifiability, estimability, causal inference and ill-posed inverse problems.
                  <i>arXiv preprint</i>
              </li>
              <li>Dablander, F.
                (<a href="https://psyarxiv.com/b3fkw">2019</a>). An Introduction to Causal Inference. <i>PsyArXiv preprint</i>
              </li>


              <li>Geiger, D., Verma, T.S., Pearl, J.
                (1989, <a href="https://arxiv.org/abs/1304.1505">2013</a>).
                d-Separation: From Theorems to Algorithms.
                UAI '89: Proceedings of the Fifth Annual Conference on Uncertainty in Artificial Intelligence. Pages 139-148
              </li>
              <li>Hernán, M., &amp; Robins, J. (2020, <a href="https://cdn1.sph.harvard.edu/wp-content/uploads/sites/1268/2021/03/ciwhatif_hernanrobins_30mar21.pdf">2021</a>).
                Causal inference: What if. Boca Raton: Chapman&amp;Hill/CRC.
              </li>
              <li>Scheines, R. (<a href="https://www.cmu.edu/dietrich/philosophy/docs/scheines/introtocausalinference.pdf">1997</a>). An Introduction to Causal Inference. Causality in Crisis? University of Notre Dame Press. Pages 185-200
              </li>
              <li>
                Coca-Perraillon, M. (<a href="https://clas.ucdenver.edu/marcelo-perraillon/content/hsr-week-2-causal-inference">2021</a>). Lectures on Causal Inference at University of Colorado Denver
              </li>
              <li>Rubin, D.B. (<a href="https://stat.columbia.edu/~cook/qr33.pdf">2003</a>).
                Basic concepts of statistical inference for causal effects in experiments and observational studies.
                Course material in Quantitative Reasoning.
              </li>

              <li>Neal, B. (<a href="https://www.bradyneal.com/Introduction_to_Causal_Inference-Aug28_2020-Neal.pdf">2020</a>.
                Introduction to Causal Inference from a Machine Learning Perspective.
                Course Lecture Notes
              </li>

              <li>Imbens, G.W. (<a href="https://arxiv.org/abs/1907.07271">2019</a>, 2020). Potential Outcome and Directed Acyclic Graph
Approaches to Causality: Relevance for
Empirical Practice in Economics. Journal of Economic Literature
              </li>

              <li>Shpitser I., VanderWeele, T., Robins, J.M. (<a href="https://arxiv.org/abs/1203.3515">2012</a>). On the Validity of Covariate Adjustment for Estimating Causal Effects
                Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010).
              </li>

              <li>Lattimore, F., Rohde, D.
                (<a href="https://medium.com/gradient-institute/causal-inference-with-bayes-rule-eed8ae45fb2e">2019</a>).
                Causal Inference with Bayes Rule. <i>Post on medium.com</i>
              </li>

              <li>Richardson, T.S., Robins, J.M.
              (<a href="https://csss.uw.edu/files/working-papers/2013/wp128.pdf">2013)
                Single World Intervention Graphs (SWIGs): A Unification of the Counterfactual and Graphical. Approaches to Causality
              </li>

              <li>Verma, T., Pearl, J. (1992, <a href="https://arxiv.org/abs/1303.5435">2013</a>). An Algorithm for Deciding if a Set of Observed Independencies
Has a Causal Explanation.  Proceedings of the Eighth Conference on Uncertainty in Artificial Intelligence.
              </li>
              <li>Shimizu, S., Hoyer, P.O., Hyvärinen, A., Kerminen, A.
                (<a href="https://www.jmlr.org/papers/volume7/shimizu06a/shimizu06a.pdf">2006</a>).
                A Linear Non-Gaussian Acyclic Model for Causal Discovery. Journal of Machine Learning Research
              </li>
              <li>Fonollosa, J.A, (<a href="https://arxiv.org/abs/1601.06680">2016</a>, 2019). Conditional Distribution Variability Measures for Causality Detection. Cause Effect Pairs in Machine Learning. The Springer Series on Challenges in Machine Learning
              </li>
              <li>Zhang, K., Hyvärinen, A.
                (2009, <a href="https://arxiv.org/abs/1205.2599">2012</a>).
                On the Identifiability of the Post-Nonlinear Causal Model. Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)
              </li>
              <li>
              Hoyer, P.O., Janzig, D., Mooij, J., Peters, J., Schölkopf, B.
              (<a href="https://papers.nips.cc/paper/2008/file/f7664060cc52bc6f3d620bcedc94a4b6-Paper.pdf">2008</a>).
              Nonlinear causal discovery with additive noise models. Proceedings of the 21st International Conference on Neural Information Processing SystemsDecember 2008 Pages 689–696
              </li>
            </ul>
            <hr/>



            <div id="causal-discovery" class="subheading mb-3">No free lunch in automatic causal discovery</div>

            <h6>(Written 20/9/2020, updated 22/10/2020)</h6>

            <p>
              After reading
              <a href="http://is.tuebingen.mpg.de/fileadmin/user_upload/files/publications/ICML2009-Mooij_[0].pdf">
                "Regression by dependence minimization and its application to causal inference in additive noise models"</a>
                by Mooij et al, even regression models seem more <i>cool</i>.
                Though this kind of regression is not exactly our old well known <a href="#linear-models">linear regression</a>, it's based on similar principles.
              </p>
              <p>Summarizing this approach, they combine regression methods and <strong>independence tests</strong>.
                Inspired by a previous research from the same group, that used
                <a href="http://webdav.tuebingen.mpg.de/causality/NIPS2008-Hoyer.pdf">
                  Gaussian Process Regression
                </a> and the
                <a href="https://www.jmlr.org/papers/volume6/gretton05a/gretton05a.pdf">
                  Hilbert-Schmidt Independence Criterion (HSIC)
                </a>.
In the new approach, to avoid making additional assumptions about the noise <strong>distribution of the residuals</strong>,
as Gaussian Process Regression does,
the authors directly propose the HSIC estimator as regression "loss function"
measuring dependence between residuals and regressors.

</p>
              <p>Published results seem promising. Anyhow, we have to be cautious, as Judea Pearl says,
                no matter how sophisticated an algorithm is,
                you will not have an automatic way to certainly infer causality from data only.

                Application of this "cool" algorithms don't get "causality" for free.
                Some previous <strong>assumptions are required</strong> to move Data Science from "data fitting" direction to "data-intensive Causal Science".
                Or as I'd rephrase, from being fully data-driven to be model-driven but data-supported.
                Or in <a href="https://twitter.com/_miguelhernan/status/897918662514024448?lang=es">
                  @_MiguelHernan</a> words: "draw your assumptions before your conclusions".
                </p>
                <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Contesting the Soul of Data-Science. Below, an introduction to the Spanish translation of <a href="https://twitter.com/hashtag/Bookofwhy?src=hash&amp;ref_src=twsrc%5Etfw">#Bookofwhy</a>:<a href="https://t.co/gWpMQEIWhX">https://t.co/gWpMQEIWhX</a>. It expresses my conviction that the data-fitting direction taken by “Data Science” is temporary, soon to be replaced by &quot;Data-intensive Causal Science&quot;</p>&mdash; Judea Pearl (@yudapearl) <a href="https://twitter.com/yudapearl/status/1280791406894694410?ref_src=twsrc%5Etfw">July 8, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js"  ></script>

            <p>
              Moreover I wonder if this epistemic limit warned by Pearl
                applies only at some deep level of knowledge but we could circumvent it in some practical scenarios.
                As Heisemberg's Uncertainty Principle applies at the micro-world but it
                can be ignored with no much penalty at the macro-world physics (with some
                <a href="https://phys.org/news/2013-02-heisenberg-uncertainty-principle-macro.html">exceptions
                </a>).
            </p>
            <p>
              Several of the previously referred articles come from the research group lead by Bernhard Schölkopf at
              <a href="http://webdav.tuebingen.mpg.de/causality/">
                Causal inference at the Max-Planck-Institute for Intelligent Systems Tübingen
              </a>.
              Reading these papers made me feel quite optimistic about the possibilities of this kind of methods.
              Particularly considering that Schölkopf and his team are aware of Pearl's work,
              and anyway they still present advances on their field.
              And benchmarks where several of these methods perform <strong>better than random</strong>.
            </p>

            <p>
              So I started by testing some features from the
              <a href="https://fentechsolutions.github.io/CausalDiscoveryToolbox/html/index.html">
                Causal Discovery Toolbox
              </a>, that in words of their creators is an
              "open-source Python package including many state-of-the-art causal modeling algorithms
              (most of which are imported from R)".
            </p>
            <p> I found some of the features very interesting, though regarding to automatic causal discovery with
              <code>cdt.causality.pairwise</code> implementations, my first results were a little disappointing.
            </p>
            <figure>
              <img src="img/cdt_experiment1.png" alt="causal discovery with cdt and boston dataset" style="border:1px solid black; width:80%;margin:auto;display:block">
              <figcaption style="text-align:center" >
                <small>Source: <a href="https://github.com/muoten/causal-discovery-playground/blob/master/boston_dataset_causal_inference_playground.ipynb">
                    https://github.com/muoten/causal-discovery-playground
                  </a>

                </small>
              </figcaption>
            </figure>
            <p>Seemingly, the <i>Additive Noise Model</i> (<code>ANM</code>) from <code>cdt.causality.pairwise</code> package was unable to
              properly determinate the cause & effect relationship between CRIM and RAD variables in the
              <a href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html">
                Boston Dataset
              </a>.
              Considering that <i>CRIM</i> was the "per capita crime rate by town"
              and <i>RAD</i> the "index of accesibility to radial highways", is unlikely that the former was a direct cause of the latter.
              Being much more likely if the arrow on the generated causal diagram was reversed.
            </p>
            <p><code>BivariateFit</code> model also provided the same weird causal direction between <i>CRIM</i>
              and <i>RAD</i>.
              While <i>Conditional Distribution Similarity Statistic</i> (<code>CDS</code>),
              <i>Information Geometric Causal Inference</i> (<code>IGCI</code>)
              and <i>Regression Error based Causal Inference</i> (<code>RECI</code>) provided the more reasonable
              opposite direction. Though all of them struggled also with other pairs as <i>NOX</i> (nitric oxides concentration
              and <i>DIS</i> (weighted distances to five Boston employment centres),
              with low average rate of success.
            </p>
            <p>Among these 5 different methods,
              only <code>CDS</code> selected the pairwise directions that make more sense:
              distance to radial highways causing effects on per capita crime rate (<i>RAD -> CRIM</i>),
              and distance to employment centres causing effects on nitric oxides concentration (<i>DIS -> NOX</i>).
            </p>
            <figure>
              <img src="img/cdt_experiment2.png" alt="causal discovery with cdt.causality.pairwise.CDS and boston dataset" style="width:70%;margin:auto;display:block">
              <figcaption style="text-align:center" >
                <small>Source: <a href="https://github.com/muoten/causal-discovery-playground/blob/master/boston_dataset_causal_inference_playground.ipynb">
                    https://github.com/muoten/causal-discovery-playground
                  </a>
                </small>
              </figcaption>
            </figure>

            <p>More details in the following
              <a href="https://github.com/muoten/causal-discovery-playground/blob/master/boston_dataset_causal_inference_playground.ipynb">
              Jupyter Notebook
              </a>.
           </p>
            <p>Curiously, I didn't know the origin of this dataset: a paper by David Harrison Jr. and Daniel L. Rubinfeld,
              published on 1978 on the Journal of Environmental Economics and Management,
              called
              <a href="https://deepblue.lib.umich.edu/handle/2027.42/22636">
                Hedonic housing prices and the demand for clean air
              </a>
            </p>

            <p>
            Finally I've tried to apply these methods to a different data set, also related to health and money,
            but not so popular, at least in the Machine Learning field: <i>life expectancy vs health expenditure</i>.
            As a context, I was playing around with
            <a href="https://github.com/muoten/life-expectancy/blob/master/life_expectancy_vs_health_expenditure_linear_regression.ipynb">
            life expectancy vs health expenditure</a> data weeks ago, using
            <a href="https://ourworldindata.org/grapher/life-expectancy?time=..&country=~OWID_WRL">Our World in Data</a> and
            WHO's <a href="http://apps.who.int/nha/database/Home/IndicatorsDownload/en">Global Health Expenditure Database (GHED)</a> as data sources.
          </p>
          <p>
            My first surprise now when applying to this data the previous 5 methods from <code>cdt.causality.pairwise</code>
            was that none of them was able to infer that
            <code>health_expenditure_log</code> was directly related to <code>health_expenditure</code>, despite the former was a calculated field by applying logarithm to the latter.
            Anyway, ignoring this point and focusing on the
            <code>health_expenditure</code> vs. <code>life_expectancy</code> relationship, only 2 of the 5 previous methods inferred the direction that I think makes more sense:
            health expenditure as cause of life expectancy.
            More details in the following <a href="https://github.com/muoten/life-expectancy/blob/master/life_expectancy_vs_health_expenditure_pairwise_causal_discovery.ipynb">
              notebook
            </a>.
          </p>
          <figure>
            <img src="img/life_expectancy_and_health_expenditure_pairwise.png" alt="causal discovery with cdt.causality.pairwise.CDS and life expectancy vs health expenditure data">
            <figcaption style="text-align:center" >
              <small>Source: <a href="https://github.com/muoten/life-expectancy/blob/master/life_expectancy_vs_health_expenditure_pairwise_causal_discovery.ipynb">
                  https://github.com/muoten/life-expectancy
                </a>
              </small>
            </figcaption>
          </figure>

          <p>
            Summarizing my first (failed) adventure on automatic causal discovery: 3 causal directions to infer, 5 tested methods,
            and only 1 of 5 succeeded for all 3 of them. By coin flipping or random guessing we would expect 1 of 8 hits.
            Getting 1 of 5 is slightly better than random. Not so bad to abandon hope,
            specially for <i>Conditional Distribution Similarity Statistic</i> (<code>CDS</code>) implementation,
            that in this little experiment succeeded as our best coin flipper. Though not so good to go deeper on this adventure by the moment.
            </p>

            <p>Still <i>no free lunch</i>... as usually.</p>

          </div>
            <br/>
            <hr/>
            <!--
            #############
          -->


            <div id="linear-models" class="subheading mb-3">Regression to Linear Regression</div>


            <h6>(2/8/2020)</h6>

            <p>
              Sometimes we can feel we know the basics and it's time to move on to something else.
              If <strong>gradient boosted trees are good enough to fit my tabular data</strong>,
              but <a href="https://xgboost.readthedocs.io/en/latest/">xgboost</a> implementation seems not efficient and accurate enough to my needs,
              I could try <a href="https://github.com/microsoft/LightGBM">lightgbm</a> or <a href="https://catboost.ai/">catboost</a>.
              Moreover, all of these algorithm implementations deal
              reasonable well even with unbalanced datasets and colinearity. So <strong>why should I care about</strong> simpler (and older) <strong>regression models?</strong>
            </p>
            <p>
              It's very healthy to never stop learning, and questioning ourselves everything. But, since a pragmatic and utilitaristic point of view...
              is it really worth the time to review the fundamentals of linear and logistic regression
              in details?
            </p>
            <figure>
              <img src="img/linear_regression_bro.jpeg" alt="Linear Regression concept in Layman Term" style="border:1px solid black; width:70%;margin:auto;display:block">
              <figcaption style="text-align:center" >
                <small>Source: https://medium.com/@sarawritezz
                  <a href="https://medium.com/swlh/this-is-how-i-explain-linear-regression-to-12-year-old-boy-using-sklearn-python-library-d4bb06a649cc">
                    This is how I explain Linear Regression to 12-Year-old Boy
                  </a>
                </small>
              </figcaption>
            </figure>
            <br/>
            <p>
              My opinion is that it's not crucial to know implementation details of algorithms to get reasonable accurate predictions
              on your validation and test sets, but... accurate predictions, out of Kaggle, many times are not the main point.
              And our search for "accuracy" often hides the requirement of generating <strong>actionable knowledge</strong>,
              that is, getting insights to make useful interventions in the <i>real world</i>.
              For this purpose it's preferable to understand our problem in terms of <strong>associations and causality</strong>.
              And be prepared to answer <i>"what if"</i> questions.
            </p>
            <!--
            <p>
              Thus... <i>what if</i> I tried to infer causal knowledge about a particular problem by using simple regressions?
            </p>
          -->

            <br/><h4>Life expectancy vs Health expenditure: Linear Regression models for Longitudinal data.</h4>

            <blockquote style='display: block;margin-top: 1em;margin-bottom: 1em;margin-left: 40px;margin-right: 40px; border:1px; content: open-quote;'>
              <p><i>Sometimes...You can't see the forest for the (Gradient Boosted) trees</i></p>
            </blockquote>
            <p>
              The great performance of <i>xgboost</i> might cause that I didn't really understand and value
              some benefits and relevant aspects of linear models.
              To better understand linear regression I've tried to compare different implementations.
              My goal was to model the main variables that affect <strong>life expectancy</strong>.
              Attempting to isolate the effect of multiple collinearities and interdependences expected between the explanatory variables.
            </p>
            <p>As this goal was quite ambitious I started by using only
              the <strong>health expenditure</strong> per capita as explanatory variable. For this purpose
              I obtained the data from the <a href="http://apps.who.int/nha/database/Home/IndicatorsDownload/en">
                WHO's Global Health Expenditure Database (GHED)
              </a>.
              Source for Life Expectancy estimates was
              <a href="https://ourworldindata.org/grapher/life-expectancy?time=..&country=~OWID_WRL">
                OurWorldInData
              </a>. More details in my
              <a href="https://github.com/muoten/life-expectancy/blob/master/life_expectancy_vs_health_expenditure_linear_regression.ipynb">
                Jupyter Notebook on github
              </a>.
            </p>
            <figure>
              <img src="img/health_expenditure_and_life_expectancy.png"
              alt="Health Expenditure and Life Expectancy" style="border:1px solid black;width:70%;margin:auto;display:block">
              <figcaption style="text-align:center">
                <small>Source: <a href="https://github.com/muoten/life-expectancy/blob/master/life_expectancy_vs_health_expenditure_linear_regression.ipynb">
                  muoten.github.io
                </a>. With data from
                <a href="https://ourworldindata.org/grapher/life-expectancy?time=..&country=~OWID_WRL">
                  OurWorldIndata
                </a> and
                <a href="http://apps.who.int/nha/database/Home/IndicatorsDownload/en">
                  WHO's Global Health Expenditure Database
                </a>
              </small>
            </figcaption>
          </figure>
          <br/>

          <p>
            Both datasets correspond to multi-dimensional data involving "measurements"
            over time. This kind of data is usually referred in statistics and econometrics,
            as <strong>longitudinal</strong> or also <strong>panel data</strong>.
          </p>
          <p>In Python there are at least 3 different packages we could use to apply linear models to our data.
            So I've compared the implementations of the following:
          </p>
          <ul>
            <li><pre>scikitlearn</pre></li>
            <li><pre>statsmodels</pre></li>
            <li><pre>linearmodels</pre></li>
          </ul>

          <p>First of all, after preparing and exploring the data, I decide to transform Health Expenditure variable by applying the natural logarithm.
          </p>
          <figure>
            <img src="img/life_expectancy_and_health_expenditure_log.png"
            alt="Health Expenditure and Life Expectancy (log)">
            <figcaption style="text-align:center"><small>Source: <a href="https://github.com/muoten/life-expectancy/blob/master/life_expectancy_vs_health_expenditure_linear_regression.ipynb">
              muoten.github.io
            </a>
          </small>
        </figcaption>
      </figure>
      <br/>
      <p>Finally we can compare the different implementations of Ordinary Least Squares.
        In the next figures, the statsmodel implementation, with a constant term (the intercept).
        Resulting in a coefficient value (beta) of <math><mn>4,32</mn></math> for the explanatory variable, with standard error of <math><mn>0,33</mn></math>.
        Assuming that <i>the covariance matrix of the errors is correctly specified</i>, as indicated in the output.
      </p>
      <figure>
        <img src="img/ols_regression_life_expectancy_vs_health_expenditure_log_metrics.png" style="border:1px solid black;width:70%;margin:auto;display:block"
        alt="Ordinary Least Squares (statsmodel): Life Expectancy vs Health Expenditure (log)">
        <figcaption style="text-align:center"><small>Source:
          <a href="https://github.com/muoten/life-expectancy/blob/master/life_expectancy_vs_health_expenditure_linear_regression.ipynb">
            muoten.github.io
          </a> Ordinary Least Squares (statsmodel): Life Expectancy vs Health Expenditure (log)
        </small>
      </figcaption>
    </figure>
    <br/>
    <figure>
      <img src="img/ols_regression_life_expectancy_vs_health_expenditure_log.png" style="border:1px solid black;width:70%;margin:auto;display:block"
      alt="Ordinary Least Squares (statsmodel): Life Expectancy vs Health Expenditure (log)">
      <figcaption style="text-align:center"><small>Source:
        <a href="https://github.com/muoten/life-expectancy/blob/master/life_expectancy_vs_health_expenditure_linear_regression.ipynb">
          muoten.github.io
        </a> Ordinary Least Squares (statsmodel): Life Expectancy vs Health Expenditure (log)
      </small>
    </figcaption>
  </figure>
  <br/>

  <p>According to our simple model the life expectancy for Spain in 2017 could be roughly estimated as
    <math><mn>79.6</mn></math><math><mo>&PlusMinus;</mo><mn>0.8</mn></math> years.

    Actually life expectancy in Spain is even higher,
    as it is one of the highest in the world. Concretely, the value in our dataset for 2017 was <math><mn>83.3</mn></math> years.
    Not bad for a single variable simple model.
  </p>

  <p>Furthermore, in the notebook they are more details about the Coefficient of Determination calculation,
    or the relation and differences between different configurations of Linear Regression models for longitudinal (panel) data.
    Finally this first analysis has been limited to Ordinary Least Squares,
    with
    <a href="http://statmath.wu.ac.at/~hauser/LVs/FinEtricsQF/FEtrics_Chp5.pdf">Fixed Effect and Random Effect variants
    </a>,
    supported by
    <a href="https://bashtage.github.io/linearmodels/doc/panel/mathematical-formula.html#panel-mathematical-notation">
      linearmodels package.
    </a>, with the names of PanelOLS and RandomEffects, respectively.
    Other alternatives, as Lasso (L1) and Ridge (L2) regularizations have been excluded from the scope, at the moment.
  </p>


  <br/>
  <h4>Linear regression. Recycling the residuals</h4>
  <p>
    The residuals in a linear regression model are the differences between the estimates and the true values.
    Besides to optimize them in order to be as small as possible, it's important to check these residuals are independent.
  </p>
  <p>
    Non random patterns in the residuals reveal our model is not good enough.
    Further, in the OLS context, random errors are assumed to produce residuals that are
    normally distributed and centered in zero. Moreover, the residuals should not be correlated with another variable, and adjacent residuals should not be correlated with each other (autocorrelation)
    <a href="https://blog.minitab.com/blog/adventures-in-statistics-2/why-you-need-to-check-your-residual-plots-for-regression-analysis">
      Reference</a>
    </p>
    <p>
      The python package <a href="https://www.scikit-yb.org/en/latest/api/regressor/residuals.html">
        yellowbrick</a> includes oneline methods to visualize ResidualPlots of a scikit-learn model.
        By plotting the residuals for the Life Expectancy vs Health Expenditure (log) LinearRegression Model of the previous example
        we can see there is indeed a pattern.
      </p>
      <figure>
        <img src="img/residuals_plot.png" style="border:1px solid black;width:70%;margin:auto;display:block"
        alt="Residuals for LinerRegression Model">
        <figcaption style="text-align:center"><small>Source: <a href="https://github.com/muoten/life-expectancy/blob/master/life_expectancy_vs_health_expenditure_linear_regression.ipynb">
          muoten.github.io</a> Residuals for Life Expectancy vs Health Expenditure (log) LinerRegression Model
        </small>
      </figcaption>
    </figure>
    <br/>



      </div>
    </div>
  </div>
</section>

<section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="covid19">
  <div class="w-100">
    <h2 class="mb-5">COVID-19</h2>



    <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5" id="covid19-estimates">
      <div class="resume-content">
        <h3 class="mb-0">Estimates and Context. Analysis and Simulations. Language matters</h3>

        <!--
        #############
      -->
      <br/>
      <div class="subheading mb-3" id="covid19-seroprevalence-bias">ENECOVID (II): Test error estimates and (my) simplified bias analysis on preliminary results

      </div>
      <h6>(Updated 21/05/2020)</h6>
      <p>
        Tests used to detect antibodies, as other kind of clinical measures don't have to be perfect to be useful.
        Generally 2 characteristics define this kind of imperfections: <strong>specificity</strong> (true negative rate) and <strong>sensitivity</strong> (true positive rate or <i>recall</i>).
        Let's say, they relate to the ability to avoid
        <strong>false positives</strong> and <strong>false negatives</strong> respectively.
      </p>
      <p>
        These two kind of errors are also known in statistics as <i>type 1</i> and <i>type 2</i> errors.
        And there is often some unbalance between their corresponding error rates.
        For clinical diagnoses these unbalance can be even desirable, as both type of errors don't have in general the same impact.
      </p>
      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">I’m not sure who made this, but I might have to stick above my desk because it’s the only way I seem to be able remember the difference between type 1 and type 2 error! <a href="https://t.co/bmk9DI30Jw">pic.twitter.com/bmk9DI30Jw</a></p>&mdash; Dr Ellen Grimås (@EllenGrimas) <a href="https://twitter.com/EllenGrimas/status/1171002176551956480?ref_src=twsrc%5Etfw">September 9, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js"  ></script>
      <p>
        But in order to quantify prevalences it's preferable that both errors compensate.
        Or making posterior adjustments if this unbalance is significant and can't be tuned.
      </p>
      <p>
        When undetected false negatives are not compensated with false positives there is <strong>misclasification bias</strong>, a kind of measure or information bias,
        depending on the taxonomy or scientific literature being consulted.
        Anyhow, independently of terminological considerations it should be adjusted in a similar way as other biases, like selection bias.
      </p>
      <p>
        Details of an applied <strong>statistical methodology</strong> to adjust a particular study similar to ENECOVID can be consulted on
        a
        <a href="https://www.medrxiv.org/content/10.1101/2020.04.14.20062463v1.full.pdf">recent paper by E. Bendavid et al</a> (April 11 2020),
        and its <a href="https://www.medrxiv.org/content/medrxiv/suppl/2020/04/17/2020.04.14.20062463.DC1/2020.04.14.20062463-1.pdf">
          statistical appendix
        </a>
        describing the procedure followed to measure the seroprevalence of antibodies to SARS-CoV-2 in Santa Clara County (California).
        I found this study via <a href="https://www.datanalytics.com/2020/04/27/muestreo-sensibilidad-y-especificidad/">@datanalytics
        </a>,
        soon accompanied by a
        <a href="https://www.datanalytics.com/2020/05/21/analisis-bayesiano-de-pruebas-con-sensibilidad-especificidad-desconocida">critical opinion</a>
        to usual improper (or lack of) methods to <strong>propagate uncertainty</strong> on the parameter estimates.
        A challenge undertaken with a
        <a href="https://bob-carpenter.github.io/diagnostic-testing/reports/specificity.pdf">
          bayesian analysis by A. Gelman et al (May 20 2020)
        </a>.
        A <strong>complex</strong> task I'm gonna ignore for my first simplified analysis.
        Though I hope to address in a near future.

        <i>Besides, further (and harder) related information can be read on the following scientific reports by
          <a href="http://www.med.mcgill.ca/epidemiology/joseph/publications/Methodological/speybroeck2012.pdf">Speybroeck et al
          </a> (2012)
        </i> or
        <a href="https://www.nature.com/articles/srep11861">M.L. Bermingham et al
        </a> (2015).

      </p>

      <h6>What about ENECOVID methodology?</h6>
      <p>
        Regarding the Spain's ENE-Covid19 serosurvey, the report with preliminary results briefly describes its technical approach to compensate for selection bias:
      </p>
      <figure>
        <img src="img/seroprevalence_and_bias_0.png" alt="Seroprevalence methodology. Method to compensate selection bias" style="border:1px solid black">
        <figcaption><small>Source: ENE-COVID19: First Round. <a href="https://www.mscbs.gob.es/ciudadanos/ene-covid/docs/ESTUDIO_ENE-COVID19_PRIMERA_RONDA_INFORME_PRELIMINAR.pdf">Preliminary results</a></small>
        </figcaption>
      </figure>
      <br/>

      <p>Furthermore an adjustment method to compensate possible misclassification bias due to test errors, similar to <a href="https://www.medrxiv.org/content/medrxiv/suppl/2020/04/17/2020.04.14.20062463.DC1/2020.04.14.20062463-1.pdf">Santa Clara's statistical approach</a>, is also detailed
        in Annex 3 of <a href="https://portalcne.isciii.es/enecovid19/documentos/ene_covid19_dis.pdf">ENECOVID study design</a>
      </p>
      <figure>
        <img src="img/seroprevalence_and_bias_4.png" alt="Seroprevalence methodology. Method to compensate misclassification bias" style="border:1px solid black">
        <figcaption><small>Source: ENE-COVID19 <a href="https://portalcne.isciii.es/enecovid19/documentos/ene_covid19_dis.pdf">study design</a></small>
        </figcaption>
      </figure>
      <br/>
      <p>
        However the report with preliminary results warns that results are provisional because of the lack of combination with immunoassay.
        And also mentions in future tense that the combination of rapid tests and immunoassay will correct the minor sensitivity of the former
        with the results of the latter to maximize the representativity and the information quality.
      </p>
      <figure>
        <img src="img/seroprevalence_and_bias_1.png" alt="Seroprevalence methodology to compensate lower sensitivity" style="border:1px solid black">
        <figcaption><small>Source: ENE-COVID19: First Round. <a href="https://www.mscbs.gob.es/ciudadanos/ene-covid/docs/ESTUDIO_ENE-COVID19_PRIMERA_RONDA_INFORME_PRELIMINAR.pdf">Preliminary report</a></small>
        </figcaption>
      </figure>

      <br/>
      <p>
        So I assume according to this claim that adjustment on sensitivity was not yet applied, and I'll try to infer in a simplified way how we could approximate the
        adjusted seroprevalence according to the current provided numbers.
      </p>
      <p>
        According to the report, rapid tests Orient GeneIgM/IgG were used, from company ZhejiangOrient Gene Biotech. Due to the difficulty of reading IgM band all the results refer to IgG.
        Manufacturer-reported sensitivity and specificity for serological detection of IgG is 97% and 100%. But these values are probably too optimistic.
        Reliability studies performed by ENE-COVID19 documented 79% sensitivity and 100% specificity for IgG.

      </p>
      <figure>
        <img src="img/seroprevalence_and_bias_2.png" alt="Seroprevalence methodology. Estimated specificity and sensitivity of rapid tests" style="border:1px solid black">
        <figcaption><small>Source: ENE-COVID19: First Round. <a href="https://www.mscbs.gob.es/ciudadanos/ene-covid/docs/ESTUDIO_ENE-COVID19_PRIMERA_RONDA_INFORME_PRELIMINAR.pdf">Preliminary results</a></small>
        </figcaption>
      </figure>
      <br/>
      <p>Annex 1 of study design provides more detail on these reliability studies. So we know 150 PCR samples were used to evaluate the rapid test, being 97 PCR+ and 53 PCR-.
        Under this benchmark global sensitivity for IgG+ was 79.4% and specificity 100%. But due to the small size of evaluated test samples
        we could provide
        more conservative estimations. For specificity our uncertainty margin could be in the interval <math><mtext>[98.1% (=53/54), 100%]</mtext></math>.
        Whereas for sensitivity we could infer that 77 true positives were detected by IgG,
        and we could estimate also a
        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3661219/figure/F3/">95% confidence interval</a> of <math><mtext>[71.4%, 87.4%]</mtext></math>.

      </p>
      <figure>
        <img src="img/test_reliability_study.png" alt="Seroprevalence methodology. Reliability study to evaluate specificity and sensitivity of rapid tests" style="border:1px solid black">
        <figcaption><small>Source: ENE-COVID19 <a href="https://portalcne.isciii.es/enecovid19/documentos/ene_covid19_dis.pdf">study design</a></small>
        </figcaption>
      </figure>
      <br/>
      <h6>Assumptions: 100% specificity, lower sensitivity</h6>
      <p>
        With 100% specificity there would be no false positives.
        And with sensitivity of 79%, for a prevalence of 5% there would be 5% of true positives and approximately 1.3% <math><mtext>(= 0.21 x 0.05 / 0.79)</mtext></math> of false negatives.
        So seroprevalence should rise to 6.3%.
        but slightly higher than preliminary 5% estimate, and also not bounded to the provided 95% confidence interval of 4.7% and 5.4%.
      </p>
      <p>I've detailed the calculation with intermediate steps on false positives and false negatives estimations. But we could use directly the expression from the previous annex:
      </p>

      <p style="text-align:center">
        <math>
          <mtext>
            Prevalence* = (Prevalence - (1 - Specificity)) / (Sensitivity - (1 - Specificity)) = 0.05 / 0.79 = 6.3%
          </mtext>
        </math>
      </p>

      <p>
        Moreover, the study refers to coherence between immunoassay, considered as "ground truth", and IgG rapid test results,
        being 97.3% for 16953 analysed samples. But... if "ground truth" was 100% reliable, specificity for IgG was 100%
        and prevalence less than 5.4% then sould be 94.6% of true negatives perfectly detected.
        So for the reminder 4.7% to 5.4% the accuracy of IgG rapid test would be approximately
        between 50% <math><mtext>(= (0.973 - 0.946) / 0.054)</mtext></math> and 42.6%
        <math><mtext>(= (0.973 - 0.953) / 0.047)</mtext></math>.
      </p>
      <p>In the worst case, considering the more pessimistic sensitivity for IgG being only 42.6%, or rounding down, <a href="https://www.theguardian.com/books/2011/feb/03/douglas-adams-42-hitchhiker?INTCMP=SRCH">42</a>%,
        which is unlikely, false negatives could approximate to 6.9% <!--(= 0.58 x 0.05 / 0.42),-->
        and estimated seroprevalence would rise to near 12%.
      </p>
      <p>Furthermore, from 247 participants with PCR+, IgG antibodies were detected on 83% <math><mtext>(76.2 - 88.2 IC 95%)</mtext></math>, as presented in the next table.
      </p>
      <figure>
        <img src="img/seroprevalence_and_bias_3.png" alt="Seroprevalence methodology. IgG detection vs PCR" style="border:1px solid black">
        <figcaption><small>Source: ENE-COVID19: First Round. <a href="https://www.mscbs.gob.es/ciudadanos/ene-covid/docs/ESTUDIO_ENE-COVID19_PRIMERA_RONDA_INFORME_PRELIMINAR.pdf">Preliminary report</a></small>
        </figcaption>
      </figure>
      <br/>
      <p>
        Assuming 100% reliability on PCR+ and 100% specificity of rapid test, IgG sensitivity could be on the interval between 76.2% and 88.2%.
        For the higher bound, 88.2%, false negatives could approximate to 0.7%
        and seroprevalence would be around 5.7%.
      </p>

      <p>
        Considering even the most optimistic scenario with 100% specificity and 97% sensitivity reported by the manufacturer,
        false negatives could approximate to 0.1% <!--(=0.03 x 0.05 / 0.97)-->.
        And 5.1% seroprevalence would be in the current provided 95% Interval of Confidence <math><mtext>(4.7%, 5.4%)</mtext></math>.
        However, with analogous calculation, if sensitivity was lower than 92%,
        seroprevalence would rise above the current provided 5.4% upper bound.
      </p>
      <h6>Assumptions: 99% specificity, 79% sensitivity</h6>
      <p>All the previous calculations based on the assumption that specificity for IgG detection was truly 100%
        as manufacturer claims and reliability studies made for ENE-COVID seemingly registered. But what if this specificity was 99%, for instance?
      </p>
      <p>
        In this case, maintaining the assumption of 79% sensitivity, true positives would have been 4.1%
        with the remainder 0.9% bein false positives, and approximately 1.1% false negatives.
        So actual prevalence would be around 5.2%, between the margins of the provided 95% IC.
        Curiously, as previously said, a worse specificity, undesirable for clinical purposes, would produce
        better raw estimates of prevalence. As long as for each 20 false negatives due to low sensitivity
        we would get 1 false positive due to imperfect specificity.
        And boths effects would compensate each other for an expected prevalence near to 5%.
      </p>

      <h6>Conclusions</h6>
      <p>While we wait for the immunoassays to be completed to "fine tune" the preliminary ENECOVID seroprevalence estimate,
        we could get some rules of thumb (or <i>cuentas de la vieja</i>) for the effects
        of expected test errors on the 5% provided average value.
        In particular, due to the relation between actual specificity and sensitivity for IgG detection
        with the rapid test Orient Gene Biotech.
      </p>
      <p>
        <u>If sensitivity and specificity for IgG were 100% and 97% as reported by the manufacturer, there would be no significant misclasification bias</u>.
      </p>
      <p>
        Otherwise, if these values approximate to those reported by reliability studies to ENECOVID, we could expect bias.
        Concretely, if sensitivity was 79%, false negative would rise the actual seroprevalence above the provided confidence interval margins.
        Unless this effect was compensated with posterior adjustment or specificity being closer to 99% instead of 100%.
      </p>
      <p>
        And particularly, <u>if specificity of rapid test was indeed 100% and sensitivity for IgG 79%, my (educated?) guess would be
          actual seroprevalence closer to 6.3%
        </u>. Additionally, a more conservative range of sensitivity estimates between (very pesimistic) 42% and (very optimistic) 97%,
        would broaden the interval of possible seroprevalence between 5.1% and 12%.
      </p>
      <p>The following chart is intended to represent adjusted seroprevalence estimates depending on the relation of specificity and sensitivity,
        for a baseline raw estimate of 5%
      </p>
      <img src="img/sensitivity_specificity_adjustment.png" alt="Sensitivity vs Specificity adjustment" style="width: 80%;">

      <br/>

      <p>
        As a limitation of the previous analysis, all the calculations presented here have been applied assuming
        that specificity and sensitivity remain independent of sex, age or presence of symptoms.
        As it's not clear if this assumption is going to be fulfilled, <a href="https://portalcne.isciii.es/enecovid19/documentos/ene_covid19_dis.pdf">ENECOVID study design</a> refers to this issue in its
        Annex 3, describing how a proper adjustment should be done. First of all, the procedure should estimate both sensitivity and specificity
        at subgroups. Subsequently, the prevalence adjustment should be applied at subgroup level before results are promediated.
      </p>

      <p>In any case, despite this possible unadjusted bias, according to the previous (quick & dirty) calculations, actual average seroprevalence in Spain would be still far from remote possibility of "herd immunity",
        though it could affect to Infection Fatality Rate estimates, for instance. And as it was mentioned in the referred preliminary ENECOVID report,
        and also remarked here just a few paragraphs before,
        <u>this sensitivity/specificity bias is expected to be corrected in the next round of results by the combination of estimates from immunoassay</u>.
      </p>
      <p>
        <i>Anyway, my provisionally inferred simplified numbers could be significantly wrong or I could be missing the point.
          In this case, or for any other comment, please,
          <a href="https://twitter.com/eoteromuras">feedback/criticism is welcome :)
          </a>
        </i>
      </p>

      <br/>
      <hr/>
      <!--
      #############
    -->
    <div class="subheading mb-3" id="covid19-seroprevalence-spain">ENECOVID (I): Preliminary results of Spain's seroprevalence study
    </div>
    <h6>(Updated 17/05/2020)</h6>
    <p>

      On 13/05/2020, <a href="https://www.mscbs.gob.es/ciudadanos/ene-covid/docs/ESTUDIO_ENE-COVID19_PRIMERA_RONDA_INFORME_PRELIMINAR.pdf">
        preliminary results</a> of Spain's seroprevalence study ENECOVID were published presenting first estimates of <strong>5% of prevalence</strong>
        of IgG antibodies for SARS-Cov2, estimating a range of uncertainty between 4.7% and 5.4% (IC 95%).
        Considering a population of 47 millions, approximately 2.3 million people would have developed antibodies.
        Same day, COVID-19 confirmed cases on Spain (<i>PCR+</i>) were 229540.
        So the <strong>estimated</strong> number of <strong>infections</strong> occured in Spain could be <strong>10 times higher</strong> than <strong>confirmed cases.</strong>
      </p>
      <p>Anyway report warns these results have to be considered <strong>provisional</strong> as they don't include yet complete information on immunoassays.
        So these estimates have to be read with caution.
      </p>
      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">A new report today from Spain showing intra-country heterogeneity of seroprevalence but overall 5%; very similar to projected in France <a href="https://twitter.com/datadista?ref_src=twsrc%5Etfw">@datadista</a> <a href="https://t.co/VUzsRPFoLu">https://t.co/VUzsRPFoLu</a><br>&quot;Only 2.3 million Spaniards have been infected w/ the coronavirus&quot;<a href="https://t.co/v09Ht86omj">https://t.co/v09Ht86omj</a> via <a href="https://twitter.com/Prodigi0_1?ref_src=twsrc%5Etfw">@Prodigi0_1</a></p>&mdash; Eric Topol (@EricTopol) <a href="https://twitter.com/EricTopol/status/1260666412164542465?ref_src=twsrc%5Etfw">May 13, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js"  ></script>

      <p>
        In summary, for this <i>serosurvey</i> approximately 60000 participants were recruited. Actually 60983 from a list of 81613, as 14549 refused to participate.
        The study observes "remarkable <strong>geographic variability</strong>".
        Concretely, prevalence estimates at province level range from a maximum of 14.2% for the province of Soria to a minimum of 1.1% for the autonomous city of Ceuta, 1.4% for Las Palmas (Canary Islands) and 1.4% the Region of Murcia.
      </p>
      <p>
        Moreover, Madrid with 11% and other inland and closer provinces from Castilla Leon (the mentioned Soria and also Segovia) and Castilla La Mancha complete the list of regions with higher estimated prevalence.
        Whereas the higher value for coastal provinces is for Barcelona with 7%. Then Malaga with 4%, Bizkaia 3.9% and neighbouring Cantabria 3.2%.
        While all the other coastal 18 provinces are below 3% threshold, including also Canary Islands and Baleares.
      </p>
      <br/>
      <p>
        My <i><u>opinion</u></i>  based on the report:
        <i>&lt;personal_bias_alert&gt;</i>
        sample size is large and the information seems very interesting.
        Though results are preliminary and should be considered vith some caution. They will be very useful to provide the basis for better-informed policies and actions.
        As long as they consolidate in the next weeks with the immunoassay data.
        Detail of methodology to be used is explained in Annex 3 of the <a href="https://portalcne.isciii.es/enecovid19/documentos/ene_covid19_dis.pdf">study design</a> (in Spanish).
      </p>
      <p>
        However it's a pity that these preliminary results are presented only in PDF, and they don't include raw data in CSV.
        Transparency but also <strong>data accesibility</strong> should not be considered a luxury. Whereas they don't conflict with other legal or ethical issues.
        Two heads are better than one. But maybe I'm just an idealistic of open source, open science and <strong>reproducible research</strong>.
        <i>&lt;/personal_bias_alert&gt;</i>
      </p>
      <p>
        Anyway... my two cents with some particular open questions, links and <strong>context</strong> regarding the methodology and the results.
      </p>

      <ul>

        <li>
          Questions on methodology:
          <ul>
            <li>could be some unadjusted measure or misclasification bias? More details in <a href="#covid19-seroprevalence-bias">next section</a></li>
            <li>could be some kind of unadjusted selection bias?</li>
          </ul>
        </li>

        <li>
          Questions on geographic variability. Some patterns seems to emerge. Can we estimate the influence of the following interrelated aspects?
          <ul>
            <li>
              population density
            </li>
            <li>proximity/<a href="https://www.medrxiv.org/content/10.1101/2020.05.09.20096339v1">
              communications to big metropolis</a>
            </li>
            <li>
              inland vs coastland, probably related to climate conditions of <a href="https://papers.ssrn.com/sol3/Papers.cfm?abstract_id=3551767">temperature and humidity</a>.
            </li>
            <li>
              cumulative incidence and transmission at the moment of lockdown measures
            </li>
          </ul>
        </li>
      </ul>

      <br/>
      <hr/>
      <!--
      #############
    -->
    <div class="subheading mb-3" id="covid19-ages">Confirmed cases by age groups: Spain vs Germany
    </div>
    <h6>(Updated 26/04/2020)</h6>

    <p>The number of confirmed cases in Germany at April 26th is around 157K people, whereas there are around 226K confirmed cases in Spain
      (<a href="https://www.arcgis.com/apps/opsdashboard/index.html#/85320e2ea5424dfaaa75ae62e5c06e61">Johns Hopkins University</a>,
      <a href="https://www.worldometers.info/coronavirus/#countries">worldometer</a>). But relative lethality estimates by COVID-19 on Germany seems below 4% (<i>confirmed deaths / confirmed cases</i>). Much lower than figures in Spain (10%)
      or Italy (13%).
    </p>
    <p>

      There are several aspects than could explain this big difference.
      But I will focus on the representativity of the sample of confirmed tests in relation to the overall population.
      If we compare the distribution of confirmed cases by age groups in Spain and Germany we can see that:
    </p>
    <ul>
      <li>
        In Spain confirmed cases are biased to ranges of older people. While young people would be underrepresented.
      </li>
      <li>
        In Germany we have just the opposite effect. Though their distribution of confirmed cases is more similar to the overall distribution, people from 60 to 79 would be slightly underrepresented, while age group of 35 to 59 would be overrepresented among confirmed cases.
      </li>
    </ul>


    <p>
      <a href="spain_covid19_by_age.html">
        <img class="covid_by_age" src="img/Spain_covid19_by_age.gif" style="width:350px" alt="Spain: covid-19 confirmed cases by age groups">
      </a>
      <a href="germany_covid19_by_age.html">
        <img class="covid_by_age" src="img/Germany_covid19_by_age.gif" style="width:350px" alt="Germany: covid-19 confirmed cases by age groups">
      </a>
    </p>
    <p>  <a href="https://github.com/muoten/life-expectancy/blob/master/covid-19/covid19_distribution_by_age.ipynb">Code</a>.
    </p>
    <p>
      Thanks to <a href="https://github.com/datadista">datadista</a>,
      <a href="https://npgeo-corona-npgeo-de.hub.arcgis.com/app/478220a4c454480e823b17327b2bf1d4">
        Robert Koch</a> Institute and plotly.
      </p>
      <p>
        Related chart, considering both age and sex groups in Spain:
      </p>

      <a href="https://www.isciii.es/QueHacemos/Servicios/VigilanciaSaludPublicaRENAVE/EnfermedadesTransmisibles/Documents/INFORMES/Informes%20COVID-19/Informe%20n%C2%BA%2025.%20Situaci%C3%B3n%20de%20COVID-19%20en%20Espa%C3%B1a%20a%2023%20de%20abril%20de%202020.pdf">
        <figure>
          <img src="img/covid19_by_age_and_sex_spain.png"  alt="COVID-19 by age and sex in Spain"/>
          <figcaption><small>Source: Red Nacional de Vigilancia Epidemiológica (RENAVE). Instituto de Salud Carlos III (ISCIII)</small>
          </figcaption>
        </figure>
      </a>

      <br/>
      <p>
        At the begining of the crisis South Korea was the country with a higher number of tests performed
        and a more representative sample in terms of age distribution. Currently,
        according to Our World in Data, Iceland has performed much more tests per capita.
        Furthermore is a reference on <a href="https://www.covid.is/english">data transparency</a>.
        <iframe src="https://ourworldindata.org/grapher/full-list-cumulative-total-tests-per-thousand?time=latest&country=ECU+EST+ISL+IND+IDN+ITA+NOR+SEN+SGP+ZAF+KOR+CHE+TWN+TUR+GBR+USA+VNM" style="width: 100%; height: 600px; border: 0px none;"></iframe>
      </p>
      <p>
        According to the number of confirmed cases and deaths with COVID-19 on Iceland,
        relative lethality for those tested positive could be below 1%.
        Actually at the time of writing is only around 0.5% in that country.
        Moreover, data from Iceland is helping to get more educated guesses on the proportion of asymptomatic infected people.
        Estimates published on April 14th on <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2006100">Spread of SARS-CoV-2 in the Icelandic Population</a>,
        report that "43% of the participants who tested positive reported having no symptoms, although symptoms almost certainly developed later in some of them.".
        Though these estimations have to be read also with caution as the effect of false positives should be taked into account.
      </p>
      <br/>

      Additional related information, though less updated:
      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Here is a distribution of recorded Covid-19 cases in Iceland (which tests broadly, even people with no symptoms) and the Netherlands (which tests narrowly, only those with severe symptoms) <a href="https://t.co/v92fVvOHrT">pic.twitter.com/v92fVvOHrT</a></p>&mdash; Alexandre Afonso (@alexandreafonso) <a href="https://twitter.com/alexandreafonso/status/1243557013759700997?ref_src=twsrc%5Etfw">March 27, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js"  ></script>

      <br/>
      Germany vs South Korea vs Italy, published on March 13th in Medium by
      <a href="https://medium.com/@andreasbackhausab/coronavirus-why-its-so-deadly-in-italy-c4200a15a7bf">
        Andreas Backhaus</a>:
        <a href="https://medium.com/@andreasbackhausab/coronavirus-why-its-so-deadly-in-italy-c4200a15a7bf">
          <figure>
            <img src="https://miro.medium.com/max/1400/1*7UiMwZS1ibeerKx-LfanEA.png"  alt="Coronavirus: why it's so deadly in Italy"/>

          </figure>
        </a>

        <br/>
        <hr/>
        <!--
        #############
      -->
      <div class="subheading mb-3" id="covid19-epcalc">Epidemic simulator: SEIR model applied to Madrid
      </div>
      <h6>(Updated 26/04/2020)</h6>

      <p>

        This <a href="https://gabgoh.github.io/COVID/index.html?CFR=0.01&D_hospital_lag=5&D_incbation=5.2&D_infectious=10&D_recovery_mild=11.1&D_recovery_severe=28.6&I0=1&InterventionAmt=0.26&InterventionTime=94.4&P_SEVERE=0.2&R0=3.9&Time_to_death=32&logN=15.761420707019587">simulator</a> implements a classical infectious disease model:
        <i>SEIR (Susceptible → Exposed → Infected → Removed)</i> [<a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)30260-9/fulltext">Wu, et. al</a>, Kucharski et. al].
        The model uses 13 parameters, including <i>Mortality statistics</i> and the <i>Basic Reproduction Number (R0)</i> before and after the <i>Intervention</i> day.
      </p>
      <p>
        I tried to adjust the evolution of confirmed deaths (<i>Fatalities</i>) in the Region of Madrid since the day this number was over N=10.
        Displacing <i>Intervention</i> day relatively to this reference. And ignoring the <i>Day 0</i> as time origin.

      </p>

      <a href="https://gabgoh.github.io/COVID/index.html?CFR=0.01&D_hospital_lag=5&D_incbation=5.2&D_infectious=10&D_recovery_mild=11.1&D_recovery_severe=28.6&I0=1&InterventionAmt=0.26&InterventionTime=94.4&P_SEVERE=0.2&R0=3.9&Time_to_death=32&logN=15.761420707019587">
        <img src="img/epcalc_madrid.png"  alt="Epidemic Calculator"/>
      </a>
      <p> Concretely, the number of reported deaths on the Region of Madrid at 14th March, when the Spanish Government decreeted
        the state of Alarm, was 213. While only 7 days before, the number was 16. And 3 weeks later this number increased from 213 to
        5136, according to <a href="https://covid19.isciii.es/resources/serie_historica_acumulados.csv">covid19.iscii.es data</a>.
      </p>
      <p>
        I used 1% as <i>Mortality Statistics</i> and 10 days for <i>T<small>inf</small> (Duration patient is infectious)</i>.
        And in order to fit the evolution of confirmed deaths R0 was established to 3.9 before the intervention
        and 1.0 after the intervention.
      </p>
      <p>
        I think the model is useful to have an idea of the interconnected variables and effects.

        But results from this model should be read with caution.
        Moreover, appart from the uncertainty introduced by many different estimated parameters and hidden variables,
        this implementation of SEIR ignores the effect of the healthcare capacity system,
        and the possibility on mortality increase due to ICU bed shortage.
      </p>
      <p>Thanks to <a href="https://github.com/gabgoh/epcalc">Gabriel Goh epcalc</a> project.
      </p>

      <br/>
      <hr/>

      <!--
      #############
    -->
    <div class="subheading mb-3" id="covid19-estimates-deaths">Reported deaths vs estimates of actual deaths</div>
    <h6>(Updated 10/04/2020)</h6>

    <p>
      The number of confirmed and notified deaths is also an estimation of actual deaths caused by the virus.
      And specially in some countries/regions this value could be highly underestimated.
      Statistics on mortality monitoring on all causes, as project <a href="https://www.euromomo.eu">EuroMomo</a> does,
      can be useful to infer alternative (and better) estimates based on excess mortality.
      This project was launched in 2008 and it uses data from a network of 29 partner Institutes from 26 countries.
      They have accessible maps with weekly estimated deviations from the baseline
      (<a href="https://www.euromomo.eu/outputs/images/z-score_lightbox.fw.png">z-scores</a>)
      from week 1 of 2010 up until today. And charts with disaggregated
      <a href="https://www.euromomo.eu/outputs/zscore_country_total.html">
        data by country and age range
      </a> for the past 4½ years.
    </p>
    <p>
      <a href="https://www.euromomo.eu">
        <img src="img/euromomo.png"  alt="euromomo.eu map 2020 week 14">
      </a>
    </p>

    <p>Despite the dramatic situation in many places, differences are still huge even for regions in the same country.
      For instance, the following charts belong to the
      <a href="https://www.isciii.es/QueHacemos/Servicios/VigilanciaSaludPublicaRENAVE/EnfermedadesTransmisibles/MoMo/Documents/informesMoMo2020/MoMo_Situacion%20a%202%20de%20abril_CNE.pdf">
        Spanish MoMo report (April 7th):
        <img src="img/momo_spain.png"  alt="euromomo Spain">
        <img src="img/momo_madrid.png"  alt="euromomo Madrid">
        <img src="img/momo_canarias.png"  alt="euromomo Canary Islands">
      </a>
    </p>
    <p>
      We can observe excess mortality has been yet dramatically huge in the second figure representing the Region of Madrid.

      However the third figure represents Canary Islands, where the first case in Spain was diagnosed.
      And it shows the impact on mortality in this region has been much lower.
    </p>

    <p>
      Fortunately, after the hard confinement measures decreed by the Spanish Government,
      both regions have current estimations of Basic Reproduction Number (R0) at April 7th near or under 1.
      According to official
      <a href="https://portalcne.isciii.es/covid19/">estimates by the Spanish Ministry of Healthcare</a>,
      R0 estimates would be 0.99 for Madrid and 0.71 for the Canary Islands.
    </p>

    <p>MoMo project in Spain collects information of aproximately 4K civil registers,
      with a coverage of the 92% of the Spanish population. Estimates of expected mortality are based
      on historical averages of observed mortality since January 1th 2008 until one year before the current date.
      This information has been published in reports in PDF format. Buth they have recently developed also an
      <a href="https://momo.isciii.es/public/momo/dashboard/momo_dashboard.html">interactive dashboard
      </a>
      with access to historical
      <a href="https://momo.isciii.es/public/momo/dashboard/momo_dashboard.html#datos">
        data in CSV
      </a> for the last 2 years.
    </p>
    <p>
      Next figure published by <a href="https://elpais.com/sociedad/2020/04/09/actualidad/1586435286_092135.html">elpais</a>
      presents both the number of deaths registered by MoMo and deaths confirmed with COVID-19 until April 2th in
      the 17 regional autonomies of Spain.
    </p>
    <img src="https://pbs.twimg.com/media/EVOt6YQU8AA2abE?format=jpg&name=medium" alt="Deaths registered by MoMo vs deaths confirmed with COVID-19 in Spain">
    <p>
      Despite this chart doesn't show the excess mortality estimates by MoMo, but the total number of deaths, we can
      see that confirmed COVID-19 deaths at april 2th in Madrid or Catalunya are even higher than the total number
      of deaths registered in these regions until April 7th. Whereas in Castilla y León and Castilla La Mancha,
      where high ratios of excess mortality have been detected, the reported COVID-19 deaths have been significantly lower.
    </p>
    <p>
      <i>Due to the <strong>latency</strong> in collecting this kind of data conclusions have to be read with <strong>caution</strong></i>.
      In some regions latency on notification would be higher than usual due to saturated Civil Registers.
      Curiously, the excess mortality estimated by MoMo at April 5th (12940) approximates a lot the 12418 COVID-19
      confirmed deaths at country level at the same date.
    </p>

    <br/>
    <hr/>
    <!--
    #############
  -->
  <div class="subheading mb-3" id="covid19-momo-spain">Reported case fatality rates vs estimates of actual fatality rates.</div>
  <h6>(Updated 6/04/2020)</h6>

  <p>
    It seems that COVID-19 virus (SARS-CoV-2) could be less lethal in relative terms than current figures we get in Italy or Spain
    (<i>estimated deaths/estimated infections</i> would be lower than <i>confirmed deaths/confirmed cases</i>).
    Though much more contagious than we expected. So <i>much more lethal in absolute terms</i>.
    With the aggravating circumstance of saturating healthcare systems
    and increasing even more the number of direct and indirect deaths caused.
  </p>

  <p>
    In <a href="https://www.mscbs.gob.es/profesionales/saludPublica/ccayes/alertasActual/nCov-China/documentos/20200404_ITCoronavirus.pdf">
      April 4th report by CCAES
    </a> (Center of Alert Coordination and Healthcare Emergencies),
    a public institution from the Spanish Ministry of Healthcare, says that mortality between overall infected
    population could be between 0.3% and 1%. They refer to an article published on The Lancet by
    <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)30567-5/fulltext">Anderson RM et al
    </a>. This is coherent with situation on
    <a href="https://www.covid.is/data">Iceland
    </a> where massive testing has been performed.
    Otherwise lethality on hospitalized cases was estimated on 14% at the beginning of the epidemy,
    according to a study by
    <a href="https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2020.25.3.2000044">Wu P. et al
    </a> in Wuhan, dated January 23th.
  </p>

  <!--
  #############
-->
<br/>
<hr/>


<div class="subheading mb-3" id=covid19-estimates-cases>Confirmed cases vs. estimates of actual infections</div>
<h6>(Updated 5/04/2020)</h6>

<p> <strong>Confirmed cases</strong> are only a (generally small and biased) subsample of actual infections.

  How small and how biased?
  It depends on the <strong>testing</strong> resources and protocols applied in each country/region.
</p>

<p>
  How many people could be actually infected all around?
  Estimations have been done by different models and analysts.
  For instance, the following values have been reported by the
  <a href="https://www.imperial.ac.uk/media/imperial-college/medicine/mrc-gida/2020-04-03-COVID19-Report-14.pdf">
    Imperial College London COVID-19 Response Team
    <img src="img/imperial_college_estimates.png"  alt="Estimates by Imperial College COVID-19 Response Team">
  </a>
</p>
<p>
  According to this model, Spain could have around 15% of infected population as of March 28th.
  But the 95% credible interval provided was between 3.7% and 41%. So the <strong>uncertainty</strong> is still huge!
  However, even the lower bound of the estimation corresponded to almost 2 million people.
  Almost 30 times higher than the number of confirmed cases in Spain at that date (72K).
</p>
<p>
  <a href="https://twitter.com/kikollan">Kiko Llaneras
  </a> et al also published at
  <a href="https://elpais.com/sociedad/2020/03/17/actualidad/1584436648_230452.html">elpais.com
  </a>
  4 different calculations, from different researchers and models, ranging from 150K to 900K expected infections
  in Spain at March 24th. When confirmed cases were below 40K according to Spanish government.
</p>
<blockquote class="twitter-tweet">
  <p lang="es" dir="ltr">🔎¿Cuántos infectados hay realmente en España?
    Seguramente cientos de miles. Repaso cuatro cálculos sencillos pero orientativos que arrojan cifras
    del orden de 300.000 o 900.000 casos: <a href="https://t.co/cACMrd9MHY">https://t.co/cACMrd9MHY</a>
  </p>&mdash; Kiko Llaneras (@kikollan)
  <a href="https://twitter.com/kikollan/status/1242759416446926848?ref_src=twsrc%5Etfw">March 25, 2020</a>
</blockquote>
<script async src="https://platform.twitter.com/widgets.js">
</script>
<p>

  While the estimations of Imperial College have been broadly communicated in mass media, often ignoring
  the main <strong>assumptions</strong> and confidence intervals underlying the gross numbers,
  I think data team at <i>elpais.com</i>, and specially Llaneras is doing a god job on communicating the numbers
  but also contextualizing assumptions under these numbers.
</p>
<p>
  Anyhow, numbers from confirmed cases and notified deaths per country, and alternative
  <strong>estimates</strong> of actual infections and deaths
  infered by different studies and models
  should be understood under their <strong>context</strong>.
  Language should be used rigourously to avoid <i>misinformation</i>.
</p>




<p> I personally recommend analysis and data curated by <a href="https://ourworldindata.org/coronavirus">Our World in Data</a>. Thanks to <a href="https://twitter.com/MaxCRoser">Max Roser</a> et al.
  I also appreciate their effort to persuade general press to use adequate terms. And to promote curated analysis from different sources:
</p>
<blockquote class="twitter-tweet">
  <p lang="en" dir="ltr">The study from Timothy Russell and coauthors estimates that only 5.8% of all symptomatic cases in Italy are reported.<a href="https://t.co/d5eRoOltBj">https://t.co/d5eRoOltBj</a>
    <br><br>Let’s hope Italy is bending the curve.<br><br>But reported cases don’t tell us much when they are likely only a small fraction of the total.
    <a href="https://t.co/QvvRtzyzVA">pic.twitter.com/QvvRtzyzVA</a></p>&mdash; Max Roser (@MaxCRoser)
    <a href="https://twitter.com/MaxCRoser/status/1245464450997649411?ref_src=twsrc%5Etfw">April 1, 2020</a>
  </blockquote>
  <script async src="https://platform.twitter.com/widgets.js"></script>


  <p> Additional info (Spanish):
  </p>
  <blockquote class="twitter-tweet"><p lang="es" dir="ltr">Como veo que hay mucho lío con las cifras de casos y muertes por coronavirus, (&quot;vamos mejor o peor que X país&quot;, &quot;el gobierno de X país miente&quot;, etc.), abro hilo explicativo para intentar que se entiendan mejor los conceptos.
    <a href="https://twitter.com/hashtag/COVID19?src=hash&amp;ref_src=twsrc%5Etfw">#COVID19</a>
    <a href="https://t.co/T2CllkjbUV">pic.twitter.com/T2CllkjbUV</a></p>&mdash; Carlos Fernández (Mejor Prevenir) (@pezcharles)
    <a href="https://twitter.com/pezcharles/status/1244643827060703232?ref_src=twsrc%5Etfw">March 30, 2020</a>
  </blockquote> <script async src="https://platform.twitter.com/widgets.js"></script>

  <br/>
  <hr/>


</div>

</div> <!--   end of <div class="resume-item"> -->





  <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5" id="covid19-data">
    <div class="resume-content">
      <h3 class="mb-0">COVID-19 Datasets</h3>
      <div class="subheading mb-3">Datasets</div>

      <ul>
        <li><a href="https://github.com/datadista/datasets/tree/master/COVID%2019">Data from Spanish government made accesible on CSV by @datadista</a>
        </li>
        <li><a href="https://momo.isciii.es/public/momo/dashboard/momo_dashboard.html#datos">Mortality by all causes (MoMo), Spain. 2 years of historical data. Daily updates</a>
        </li>
        <li><a href="https://www.covid.is/data">COVID-19 in Iceland – Statistics</a>
        </li>
        <li><a href="https://covidtracking.com/api">The COVID Tracking Project (US)</a>
        </li>
        <li><a href="https://aws.amazon.com/es/data-exchange/covid-19">Data related to COVID-19 available at AWS Data Exchange</a>
        </li>
        <li><a href="https://www.google.com/covid19/mobility/">Google COVID-19 Community Mobility Reports</a>
        </li>
        <li><a href="https://datos.civio.es/dataset/pcr-coronavirus-covid19-espana-comunidades-autonomas/">PCR tests performed by the Autonomous Communities of Spain that communicate these data. By Civio Datos (Spanish)</a>
        </li>
        <li><a href="https://rubenfcasal.github.io/COVID-19/">COVID-19 Data in Spain. By rubenfcasal (Spanish)</a>
        </li>
      </ul>

      <div class="subheading mb-3">Dashboards</div>

      <ul>
        <li><a href="https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6">Coronavirus COVID-19 Global Cases by the CSSE at John Hopkins University</a>
        </li>
        <li><a href="https://www.worldometers.info/coronavirus/#countries">Worldometer. Confirmed Cases and Deaths by Country, Territory or Conveyance</a>
        </li>
        <li><a href="https://experience.arcgis.com/experience/7e30edc490a5441a874f9efe67bd8b89">Official Update of COVID-19 Situation in Singapore</a>
        </li>
        <li><a href="https://datastudio.google.com/u/0/reporting/91350339-2c97-49b5-92b8-965996530f00/page/RdlHB">Date from Italy by Italian Civil Protection Department. Dashboard by @FMossotto</a>
        </li>
      </ul>

      <div class="subheading mb-3">Reports, articles, papers...</div>

      <ul>
        <li><a href="https://ourworldindata.org/coronavirus">Our World in Data. Coronavirus Disease (COVID-19) – Statistics and Research</a>
        </li>
        <li id="euromomo">
          <a href="https://www.euromomo.eu/">EuroMomo: European Monitoring of Excess Mortality for Publich Health Action</a>
        </li>
        <li>
          <a href="https://www.imperial.ac.uk/media/imperial-college/medicine/mrc-gida/2020-04-03-COVID19-Report-14.pdf">
            Report 14: OnlineCommunity Involvement in COVID-19 Research &amp; Outbreak Response. Pristera P. et al. Imperial College
          </a>
        </li>
        <li>
          <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)30260-9/fulltext">
            Nowcasting and forecasting the potential domestic and international spread of the 2019-nCoV outbreak originating in Wuhan, China: a modelling study. Wu J.T. et al. The Lancet. Jan 31,2020
          </a>
        </li>
        <li>
          <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2006100">Spread of SARS-CoV-2 in the Icelandic Population. Gudbjartsson D. et al. The New England Journal of Medicine. April 14th. </a>
        </li>
        <li><a href="https://www.ine.es/covid/covid_movilidad_en.htm">Statistical information for the analysis of the impact of the COVID-19 crisis / Mobility Data. By Spanish INE. With collaboration of the three main mobile operators in Spain (Orange, Telefonica, Vodafone)</a>
        </li>
        <li>
          <a href="https://ncase.me/covid-19/">What Happens Next? COVID-19 Futures, Explained With Playable Simulations (by Marcel Salathé (epidemiologist) & Nicky Case (art/code) 1/05/2020)</a>
        </li>
        <li>
          <a href="https://ourworldindata.org/policy-responses-covid">Policy Responses to the Coronavirus Pandemic (ourworldindata.org 8/05/2020)</a>
        </li>

      </ul>

      <p>
        Seroprevalence analysis, adjustment for selection and misclasification bias:
      </p>
      <ul>
        <li>
          <a href="https://www.medrxiv.org/content/10.1101/2020.04.14.20062463v1.full.pdf">COVID-19 Antibody Seroprevalence in Santa Clara County, California by E. Bendavid et al (April 11 2020)</a>
        </li>
        <li>
          <a href="https://www.medrxiv.org/content/medrxiv/suppl/2020/04/17/2020.04.14.20062463.DC1/2020.04.14.20062463-1.pdf">
            COVID-19 Antibody Seroprevalence in Santa Clara County. Statistical Appendix</a>,
            <a href="https://www.nature.com/articles/srep11861">Hui and Walter’s latent-class model extended to estimate diagnostic test properties from surveillance data: a latent model for latent dataM.L. Bermingham et al, 2015, Nature</a>
          </li>
          <li>
            <a href="http://www.med.mcgill.ca/epidemiology/joseph/publications/Methodological/speybroeck2012.pdf">Misclassification errors in prevalence estimation: Bayesianhandling with care. Speybroeck et al 2012. Int J Public Health</a>
          </li>
          <li>
            <a href="https://bob-carpenter.github.io/diagnostic-testing/reports/specificity.pdf">Bayesian analysis of tests with unknown specificity and sensitivity. Gelman et al (20 May 2020)</a>
          </li>
        </ul>

        <p>Spanish only:
        </p>
        <ul>
          <li><a href="https://elpais.com/sociedad/2020/04/03/actualidad/1585936102_333545.html">Así evoluciona la curva del coronavirus en España y en cada autonomía (elpais.com)</a>
          </li>
          <li>
            <a href="https://www.isciii.es/QueHacemos/Servicios/VigilanciaSaludPublicaRENAVE/EnfermedadesTransmisibles/MoMo/Documents/informesMoMo2020/MoMo_Situacion%20a%207%20de%20abril_CNE.pdf">Vigilancia de los excesos de mortalidad por todas las causas. MoMo (Situación a 7/4/2020)</a>
          </li>
          <li>
            <a href="https://www.isciii.es/QueHacemos/Servicios/VigilanciaSaludPublicaRENAVE/EnfermedadesTransmisibles/Documents/INFORMES/Informes%20COVID-19/Informe%20n%C2%BA%2025.%20Situaci%C3%B3n%20de%20COVID-19%20en%20Espa%C3%B1a%20a%2023%20de%20abril%20de%202020.pdf">Informe sobre la situación de COVID-19 en España. 23 abril 2020. RENAVE. CNE. CNM (ISCIII)</a>
          </li>
          <li>
            <a href="https://www.mscbs.gob.es/profesionales/saludPublica/ccayes/alertasActual/nCov-China/documentos/20200404_ITCoronavirus.pdf">Información científica-técnica. Enfermedad por coronavirus, COVID-19 (mscbs.gob.es, 4/04/2020)</a>
          </li>
          <li>
            <a href="https://www.elconfidencial.com/tecnologia/ciencia/2020-04-03/covid19-test-pcr-coronavirus-espana_2531844/">Razones (fundamentadas) por las que España no está haciendo esos 20000 test PCR al día (El Confidencial, 3/04/2020)</a>
          </li>
          <li>
            <a href="https://civio.es/medicamentalia/2020/04/08/coronavirus-sars-cov-2-pruebas-pcr-espana/">Sin medios contra el coronavirus: cómo España intentó huir a ciegas del "tsunami" (CIVIO, 8/04/2020)</a>
          </li>
          <li>
            <a href="https://www.eldiario.es/sociedad/muertes-semana-dispara-mortalidad-coronavirus_0_1022248648.html">30.000 muertes que no esperábamos: así evoluciona la peor crisis de mortalidad desde el inicio de la democracia (eldiario.es 3/05/2020)</a>
          </li>
          <li>
            <a href="https://elpais.com/sociedad/2020/04/25/actualidad/1587831599_926231.html">8.000 muertes sin contabilizar: así evoluciona el exceso de fallecidos en España y cada autonomía (elpais.com 8/05/2020)</a>
          </li>
          <li>
            <a href="https://www.mscbs.gob.es/ciudadanos/ene-covid/docs/ESTUDIO_ENE-COVID19_PRIMERA_RONDA_INFORME_PRELIMINAR.pdf">Estudio ENE-COVID19. Primera ronda. Informe preliminar (Spanish Government, 13-05-2020)</a>
          </li>
          <li>
            <a href="https://www.datanalytics.com/2020/04/27/muestreo-sensibilidad-y-especificidad/">Muestreo, sensibilidad y especificidad, por datanalytics</a>
          </li>
          <li>
            <a href="https://portalcne.isciii.es/enecovid19/documentos/ene_covid19_dis.pdf">Diseño del estudio ENE-COVID19</a>
          </li>
          <li><a href="https://www.elconfidencial.com/espana/2020-05-20/grafico-muertes-coronavirus-espana-siglo-xxi_2599704/">El gráfico que muestra cómo el covid-19 ha roto todos los registros de muertes del siglo (elconfidencial.com, 20-05-2020)</a>
          </li>
          <li>
            <a href="https://www.datanalytics.com/2020/05/21/analisis-bayesiano-de-pruebas-con-sensibilidad-especificidad-desconocida/">Análisis (bayesiano) de pruebas con sensibilidad/especificidad desconocida (datanalytics 21-05-2020)</a>
          </li>
        </ul>



      </div>
      <div class="resume-date text-md-right">
        <span class="text-primary">17/5/2020</span>
      </div>
    </div>

  </div>

</section>

<hr class="m-0">

<section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="others">
  <div class="w-100">
    <h2 class="mb-5">Other topics</h2>

    <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5" id="audio2vec">
      <div class="resume-content">
        <h3 class="mb-0">Chromaprint2vec</h3>
        <div class="subheading mb-3">Audio fingerprints: similarity between songs</div>
         <p>
          Based on <a href="https://acoustid.org/chromaprint">Acoustid Chromaprint</a> and the <a href="https://musicbrainz.org/">MusicBrainz database</a>
        </p>
        <a href="https://github.com/muoten/chromaprint2vec">Code</a>
         <p>
          <a href="https://github.com/muoten/chromaprint2vec">
            <img src="img/projector_example.png"  alt="Chromaprint2vec on embedding-projector"/>
          </a>
        </p>


      </div>
      <div class="resume-date text-md-right">
        <span class="text-primary">Sep 2024</span>
      </div>
    </div>

    <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5" id="computervision">
      <div class="resume-content">
        <h3 class="mb-0">Car Behavioral Cloning</h3>
        <div class="subheading mb-3">Computer Vision models: Deep Learning vs classical Machine Learning</div>
        <p>Deep Learning: Agárrate que vienen curvas / Hold on come curves
        </p>
        <p>
          Custom workshop materials on Deep Learning and classical Machine Learning applied self-driving car simulator. Based on <a href="https://github.com/udacity/CarND-Behavioral-Cloning-P3">Udacity CarND Behavioral Cloning Project</a> and the <a href="https://devblogs.nvidia.com/deep-learning-self-driving-cars/">NVIDIA Convolutional Neural Network model</a>
        </p>
        <p>
          <a href="https://github.com/muoten/car-behavioral-cloning">
            <img src="img/lake_track.png"  alt="Car Behavioral Cloning"/>
            Code
          </a>
        </p>
        <p>Thanks to UDACITY, Nvidia, Keras and <a href="https://github.com/naokishibuya/car-behavioral-cloning">Naoki Shibuya</a> first implementation of car-behavioral-cloning project.
          And also to my colleague <a href="https://github.com/kingkastle">Rafa Castillo</a> and the <a href="https://www.meetup.com/es-ES/meetup-group-ICEMD/events/261039964/">ICEMD</a>.
        </p>

      </div>
      <div class="resume-date text-md-right">
        <span class="text-primary">May 2019</span>
      </div>
    </div>
  </div>

</section>

<hr class="m-0">

<section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="hacks">
  <div class="w-100">
    <h2 class="mb-5">Hackathons &amp; Demos</h2>

    <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
      <div class="resume-content">
        <h3 class="mb-0">Diversifynd</h3>
        <div class="subheading mb-3">Hackathon StartMeApp Artificial Intelligence 2019</div>
        <p>
          <strong>Diversifynd</strong> is a platform that supports diversity.
        </p>
        <p>Users can check which events or organizations have a better degree of representation in term of gender or race.
          For this purpose computer vision is applied to images of these events or organizations. By traning our custom model.
        </p>
        <p><a href="https://github.com/muoten/diversityscore">
          <img src="img/thealfredolambdas_hackathon.png"  alt="Diversifynd"/>
          Code
        </a>
      </p>
      <p>
        Developed by <i><a href="https://twitter.com/info_hoss/status/1097551695947677696">TheAlfredoLambdas</a></i> (magnificent) team.
        Thanks also to Tensorflow/serving, FaceNet and a project by <a href="https://medium.com/@zhuyan/gender-and-race-recognition-transfer-multi-task-learning-for-the-laziest-88316e6e492"> Zhu Yan</a> And also heroku, azure, docker...
      </p>

    </div>
    <div class="resume-date text-md-right">
      <span class="text-primary">Dic 2018</span>
    </div>
  </div>

  <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="resume-content">
      <h3 class="mb-0">Augmented Choices</h3>
      <div class="subheading mb-3">Hackatrips. Minube and Fitur</div>
      <p><strong>Augmented Choices</strong>: Personalized and Gamified Trip Experiences with Augmented Reality.
      </p>
      <p>
        <a href="https://github.com/muoten/augmented-choices">Code.
        </a>
      </p>
      <p>Developed by <i>TheAlfredoLambdas</i> (splendiferous) team.
        Thanks also to Minube API, Oracle Cloud Platform Container Service, Hotelscombined API...
      </p>
    </div>
    <div class="resume-date text-md-right">
      <span class="text-primary">Jan 2018</span>
    </div>
  </div>

  <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="resume-content">
      <h3 class="mb-0">Berlin &amp; Berlout</h3>
      <div class="subheading mb-3">Techcrunch Disrupt Hackathon Berlin</div>
      <p>Could you get into a berlin exclusive nightclub?
        <strong>Berlout</strong> tells users if they fit the admission criteria for Berlin clubs:
        dark clothes, no jeans, no more than 3 people, around 30s, no laughing, no drinks...

        You only have to take a picture.
        And <i>computer vision</i> algorithm identifies elements related with your probability of being rejected.
        You will see what clubs you could enter with more chances according to this evaluation.
      </p>

      <p>
        <a href="https://github.com/muoten/augmented-choices">
          <img src="img/berlout_screenshot.jpg"  alt="Berlin/Berlout"/>
          Code.
        </a>
      </p>
      <p>Team work. Thanks to <a href="https://twitter.com/chus9000@">Jesus Martín</a> and the rest of the (marvelous) team! Thanks also to Microsoft Azure Cognitive Services, and Techcrunch, and the <a href="https://techcrunch.com/2017/12/03/unicorn-battle/">unicorns</a>...
      </p>
    </div>
    <div class="resume-date text-md-right">
      <span class="text-primary">Dec 2017</span>
    </div>
  </div>

</div>


</section>


</div>

<!-- Bootstrap core JavaScript -->
<script src="vendor/jquery/jquery.min.js"></script>
<script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

<!-- Plugin JavaScript -->
<script src="vendor/jquery-easing/jquery.easing.min.js"></script>

<!-- Custom scripts for this template -->
<script src="js/resume.min.js"></script>

</body>
</html>
